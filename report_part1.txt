a. We have used the twitter tokenizer from nltk python's library, together with a list of contractions for which we have used the nltk's word tokenizer in order to obtain a better accuracy.
We have conducted a comparison between the nltk's word tokenizer and the nltk's twitter tokenizer which led us to the conclusion that the first one is more accurate for contracted forms such as (we're, I'm, can't), while the second one is more suited for social media data, where the used language is closer to the user, thus often containing unconventional words and phrases (abbreviations, links, emojis, shortening of the words, jargon, etc.). 
Output of the first 20 messages in the corpus:
