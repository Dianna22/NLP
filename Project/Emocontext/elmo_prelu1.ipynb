{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "elmo-prelu1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dianna22/NLP/blob/master/Project/Emocontext/elmo_prelu1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4yNrZNr2LXw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "670d6515-e241-4cbf-9580-f7809f8026f2"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q emoji"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    24% |████████                        | 10kB 20.3MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 20kB 1.8MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 30kB 2.6MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 40kB 3.4MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cNbKcFbbWnRO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOiQzEW2Xltz",
        "colab_type": "code",
        "outputId": "a1a9f12f-a607-408b-e859-ebf10dc752b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fVMswhWzXlj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "#   f.write('Hello Google Drive!')\n",
        "# !cat /content/gdrive/My\\ Drive/foo.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21j_GjDXJvIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b627970f-3929-4ed1-867d-8d71797e7959"
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import emoji\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
        "from keras.layers import Dropout, Input, TimeDistributed, PReLU\n",
        "from keras.models import Sequential, Model, load_model, save_model, model_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import regularizers\n",
        "from keras.utils import to_categorical\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import time"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0408 15:30:51.560894 140451576448896 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5EaTL-bkKB_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)\n",
        "\n",
        "class ElmoEmbeddingLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.dimensions = 1024\n",
        "        self.trainable=True\n",
        "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
        "                               name=\"{}_module\".format(self.name))\n",
        "\n",
        "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
        "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
        "                      as_dict=True,\n",
        "                      signature='default',\n",
        "                      )['default']\n",
        "        return result\n",
        "\n",
        "#     def compute_mask(self, inputs, mask=None):\n",
        "#         return K.not_equal(inputs, '--PAD--')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.dimensions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulokFrhSYBAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_prefix='/content/gdrive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVO2OpyqKCRn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvzGGQDkKCMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_FILE = path_prefix + 'train.txt'\n",
        "DEV_FILE =  path_prefix + 'dev.txt'\n",
        "TEST_FILE =  path_prefix + 'test.txt'\n",
        "\n",
        "TURNS_NAMES = [\"turn1\", \"turn2\", \"turn3\"]\n",
        "LABEL = [\"label\"]\n",
        "CONCATENATED_TURNS = \"turns\"\n",
        "def parse_file(file_path):\n",
        "    output_dict = dict()\n",
        "    with open(file_path, newline='\\n', encoding='utf8') as csvfile:\n",
        "        return pd.read_csv(csvfile, sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vPp3GqTLpP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_CHECKPOINT = path_prefix + '3_elmo-soa-adam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlvvfyEcKCQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = parse_file(TRAIN_FILE)\n",
        "dev_data = parse_file(DEV_FILE)\n",
        "test_data = parse_file(TEST_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjlDYAH_Lgzp",
        "colab_type": "code",
        "outputId": "5d947a89-f012-4d0e-d36a-a34fe684c806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.shape(train_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30160, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "40M3KQQmKCWf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concatenate_turns(df, delim=\"fullstop\"):\n",
        "    turns = [(\"%s %s %s %s %s\" %\n",
        "                 (row[TURNS_NAMES[0]], delim,\n",
        "                  row[TURNS_NAMES[1]], delim,\n",
        "                  row[TURNS_NAMES[2]])).lower()\n",
        "                 for index, row in df.iterrows()]\n",
        "    df[CONCATENATED_TURNS] = pd.Series(turns, index=df.index)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ffWsWOElKCXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def emoticons_replace(df):\n",
        "    for index, row in df.iterrows():\n",
        "        turns = emoji.demojize(row[CONCATENATED_TURNS])\n",
        "        # remove delimiters \":\"  (:smiley: -> smiley)\n",
        "        for emoj in re.findall(\":\\w*:\", turns):\n",
        "            turns  = turns.replace(emoj, emoj[1:-1])\n",
        "        df.at[index, CONCATENATED_TURNS] = turns\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DougW0jJLSr5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = emoticons_replace(concatenate_turns(train_data))\n",
        "dev = emoticons_replace(concatenate_turns(dev_data))\n",
        "test = emoticons_replace(concatenate_turns(test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEnP1ua9Lljb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_sentence = 189 # 163,82,189\n",
        "### angry: [1 0 0 0]\n",
        "### happy: [0 1 0 0]\n",
        "### others: [0 0 1 0]\n",
        "### sad: [0 0 0 1]\n",
        "labels = {0: 'angry',\n",
        "          1: 'happy',\n",
        "          2: 'others',\n",
        "          3: 'sad'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xA-W8YxHLlve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### angry: [1 0 0 0]\n",
        "### happy: [0 1 0 0]\n",
        "### others: [0 0 1 0]\n",
        "### sad: [0 0 0 1]\n",
        "Y_train = pd.get_dummies(train[LABEL]).as_matrix()\n",
        "# for i, t in enumerate(train[LABEL].iterrows()):\n",
        "#     if t[1]['label']=='others':\n",
        "#         print(Y_train[i])\n",
        "#         break\n",
        "Y_dev = pd.get_dummies(dev[LABEL]).as_matrix()\n",
        "Y_test = pd.get_dummies(test[LABEL]).as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TQu-fylnLpHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Metrics(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.val_f1s = []\n",
        "        self.val_recalls = []\n",
        "        self.val_precisions = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
        "        val_targ = self.validation_data[1]\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average='micro')\n",
        "        _val_recall = recall_score(val_targ, val_predict, average='micro')\n",
        "        _val_precision = precision_score(val_targ, val_predict, average='micro')\n",
        "        print(_val_f1)\n",
        "        print(_val_recall)\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        print(\"— val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
        "        f1 = print_metrics_predicted(val_predict, val_targ, MODEL_CHECKPOINT+\"-results\")\n",
        "        if f1 >max_f1:\n",
        "          self.model.save(MODEL_CHECKPOINT)\n",
        "        return\n",
        " \n",
        "metrics = Metrics()\n",
        "\n",
        "def print_metrics_predicted(predicts,Y,filename):\n",
        "    tp =[0,0,0,0]\n",
        "    fp =[0,0,0,0]\n",
        "    fn =[0,0,0,0]\n",
        "    for i,pred in enumerate(predicts):\n",
        "        p = np.argmax(pred)\n",
        "        y = np.argmax(Y[i])\n",
        "        if p == y:\n",
        "            tp[p] += 1\n",
        "        else:\n",
        "            fp[p] +=1\n",
        "            fn[y] +=1\n",
        "    prec = sum(tp)/(sum(tp+fp)+np.finfo(float).eps)\n",
        "    rec = sum(tp)/(sum(tp+fn)+np.finfo(float).eps)\n",
        "    with open(filename, \"w\") as f:\n",
        "      print(\"F1 all\")\n",
        "      f1_all = 2*prec*rec/(prec+rec+np.finfo(float).eps)\n",
        "      print(f1_all) \n",
        "      f.write(str(f1_all))\n",
        "      print(\"***\")\n",
        "      for i in range(4):\n",
        "          print(\"F1 %s: \" % labels[i])\n",
        "          f.write(\"\\n%s: \" % labels[i])\n",
        "          prec = tp[i]/(tp[i]+fp[i]+np.finfo(float).eps)\n",
        "          rec = tp[i]/(tp[i]+fn[i]+np.finfo(float).eps)\n",
        "          f1 = 2*prec*rec/(prec+rec+np.finfo(float).eps)\n",
        "          print(f1)\n",
        "          f.write(str(f1))\n",
        "          print(\"****\")\n",
        "      tp.pop(2)\n",
        "      fp.pop(2)\n",
        "      fn.pop(2)\n",
        "      print(\"F1 happy angry sad\")\n",
        "      f.write(\"\\nF1 happy angry sad: \")\n",
        "      prec = sum(tp)/(sum(tp+fp)+np.finfo(float).eps)\n",
        "      rec = sum(tp)/(sum(tp+fn)+np.finfo(float).eps)\n",
        "      f1= 2*prec*rec/(prec+rec+np.finfo(float).eps)\n",
        "      f.write(str(f1))\n",
        "      print(f1)\n",
        "      return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDGkgcupLpLD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vocabulary_size = len(tokenizer.word_counts) + 1\n",
        "\n",
        "epochs = 10\n",
        "embed_dim = 256\n",
        "lstm_out = 128\n",
        "batch_size = 128\n",
        "drop_out = 0.3\n",
        "loss_fct = 'binary_crossentropy'\n",
        "activation_fct = 'softmax'\n",
        "optimizer = \"Adam-0.01\"\n",
        "\n",
        "parameters = \"\"\"Epochs:%s\\nEmbed_dim: %s\\nLstm_out: %s\\nBatch size: %s\\nDrop_out: %s\n",
        "Loss_fct: %s\\nActivaion_fct: %s\\nOptimizer: %s\\n\n",
        "\"\"\" %(str(epochs), str(embed_dim), str(lstm_out), str(batch_size), str(drop_out), loss_fct,\n",
        "      activation_fct, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rkRYZPI_kZak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_layer = Input(shape=(max_sentence,), dtype='int32')\n",
        "\n",
        "# embedding_layer = Embedding(vocabulary_size,\n",
        "#                             embed_dim,\n",
        "#                             weights=[embedding_matrix],\n",
        "#                             input_length=max_sentence,\n",
        "#                             trainable=False)(input_layer)\n",
        "# bi_lstm = Bidirectional(LSTM(lstm_out))(embedding_layer)\n",
        "# dropout = Dropout(0.4)(bi_lstm)\n",
        "# dense = Dense(128,activation=activation_fct)(dropout)\n",
        "# dropout = Dropout(0.2)(dense)\n",
        "# dense = Dense(4,activation=activation_fct)(dropout)\n",
        "# adam = optimizers.Adam(lr=0.01)\n",
        "# rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n",
        "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "# model = Model(inputs=[input_layer], outputs=dense)\n",
        "# model.compile(loss = loss_fct, optimizer=adam, metrics = ['accuracy'])\n",
        "# print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozc-ywX5kftE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a14bb029-723e-4e41-a442-2406886b250b"
      },
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(1,), dtype=\"string\")\n",
        "embedding = ElmoEmbeddingLayer()(input_layer)\n",
        "# bilstm = Bidirectional(LSTM(lstm_out), input_shape=(1024,))(embedding)dr = Dropout(0.4)(embedding)\n",
        "dropout = Dropout(0.4)(embedding)\n",
        "dense = Dense(128,activation=activation_fct)(dropout)\n",
        "dropout = Dropout(0.2)(dense)\n",
        "dense = Dense(4,activation=activation_fct)(dropout)\n",
        "\n",
        "adam = optimizers.Adam(lr=0.01)\n",
        "rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=dense)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=adam, metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0408 15:33:01.979829 140451576448896 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "elmo_embedding_layer_3 (Elmo (None, 1024)              4         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 131,720\n",
            "Trainable params: 131,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MwJ8c48tLpMD",
        "colab_type": "code",
        "outputId": "e66ada3a-1c39-4296-a562-3d2ad6e470bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "cell_type": "code",
      "source": [
        "input_text = Input(shape=(1,), dtype=\"string\")\n",
        "embedding = ElmoEmbeddingLayer()(input_text)\n",
        "# bilstm = Bidirectional(LSTM(lstm_out), input_shape=(1024,))(embedding)dr = Dropout(0.4)(embedding)\n",
        "dense = Dense(1024, activation='relu')(embedding)\n",
        "dense = Dense(512, activation='relu')(dense)\n",
        "dense = Dropout(0.15)(dense)\n",
        "dense = Dense(128, activation='relu')(dense)\n",
        "dense = Dropout(0.1)(dense)\n",
        "pred = Dense(4, activation='softmax')(dense)\n",
        "\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "adam = optimizers.Adam(lr=0.003)\n",
        "model.compile(loss='mean_squared_error', optimizer= adam, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0405 20:13:32.367329 139666891708288 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "elmo_embedding_layer_4 (Elmo (None, 1024)              4         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 1,640,584\n",
            "Trainable params: 1,640,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JzWU4A2uLpGa",
        "colab_type": "code",
        "outputId": "29857e8e-6f48-4c1f-9695-8a9d6d469b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7500
        }
      },
      "cell_type": "code",
      "source": [
        "max_f1 = 0\n",
        "model.fit(train[CONCATENATED_TURNS], Y_train, epochs=100, verbose=1,\n",
        "          batch_size=128,\n",
        "          validation_data=(dev[CONCATENATED_TURNS], Y_dev),\n",
        "          callbacks=[metrics,\n",
        "                     EarlyStopping(patience=5),\n",
        "                     ModelCheckpoint(MODEL_CHECKPOINT, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "                    ])\n",
        "#0.32-0.34\n",
        "#0.26-0.37\n",
        "#-droppout\n",
        "#0.37-0.40\n",
        "#+prelu\n",
        "#0.36-0.37\n",
        "#-prelu\n",
        "# 0.33-0.46\n",
        "# mse\n",
        "# 0.44 - loss 0.08 val loss 0.08\n",
        "# adam 0.03\n",
        "with open(MODEL_CHECKPOINT + \".json\",\"w\") as f:\n",
        "  f.write(model.to_json())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0408 15:33:08.297775 140451576448896 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 30160 samples, validate on 2755 samples\n",
            "Epoch 1/100\n",
            "30160/30160 [==============================] - 335s 11ms/step - loss: 0.4458 - acc: 0.7975 - val_loss: 0.2927 - val_acc: 0.8745\n",
            "0.6912579957356076\n",
            "0.5883847549909256\n",
            "— val_f1: 0.691258 — val_precision: 0.837726 — val_recall 0.588385\n",
            "F1 all\n",
            "0.6010889292196007\n",
            "***\n",
            "F1 angry: \n",
            "0.2051282051282051\n",
            "****\n",
            "F1 happy: \n",
            "0.2949308755760368\n",
            "****\n",
            "F1 others: \n",
            "0.7572314049586775\n",
            "****\n",
            "F1 sad: \n",
            "0.3468208092485548\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.23199023199023192\n",
            "\n",
            "Epoch 00001: val_loss improved from -inf to 0.29267, saving model to /content/gdrive/My Drive/3_elmo-soa-adam\n",
            "Epoch 2/100\n",
            "30160/30160 [==============================] - 299s 10ms/step - loss: 0.3964 - acc: 0.8247 - val_loss: 0.2710 - val_acc: 0.8912\n",
            "0.7438653417156763\n",
            "0.6656987295825771\n",
            "— val_f1: 0.743865 — val_precision: 0.842831 — val_recall 0.665699\n",
            "F1 all\n",
            "0.6762250453720507\n",
            "***\n",
            "F1 angry: \n",
            "0.2478048780487804\n",
            "****\n",
            "F1 happy: \n",
            "0.30909090909090897\n",
            "****\n",
            "F1 others: \n",
            "0.815757279177881\n",
            "****\n",
            "F1 sad: \n",
            "0.3932584269662921\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.27547434996486286\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.29267\n",
            "Epoch 3/100\n",
            "30160/30160 [==============================] - 298s 10ms/step - loss: 0.3836 - acc: 0.8335 - val_loss: 0.2699 - val_acc: 0.8928\n",
            "0.7567018683996751\n",
            "0.6762250453720509\n",
            "— val_f1: 0.756702 — val_precision: 0.858921 — val_recall 0.676225\n",
            "F1 all\n",
            "0.6889292196007258\n",
            "***\n",
            "F1 angry: \n",
            "0.26752966558791796\n",
            "****\n",
            "F1 happy: \n",
            "0.3837638376383763\n",
            "****\n",
            "F1 others: \n",
            "0.8174895603045932\n",
            "****\n",
            "F1 sad: \n",
            "0.4813278008298755\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.3252258512856149\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.29267\n",
            "Epoch 4/100\n",
            "30160/30160 [==============================] - 298s 10ms/step - loss: 0.3791 - acc: 0.8366 - val_loss: 0.2554 - val_acc: 0.8997\n",
            "0.7725982975273612\n",
            "0.6918330308529945\n",
            "— val_f1: 0.772598 — val_precision: 0.874713 — val_recall 0.691833\n",
            "F1 all\n",
            "0.7049001814882031\n",
            "***\n",
            "F1 angry: \n",
            "0.2622576966932724\n",
            "****\n",
            "F1 happy: \n",
            "0.4169884169884169\n",
            "****\n",
            "F1 others: \n",
            "0.8288201160541585\n",
            "****\n",
            "F1 sad: \n",
            "0.495798319327731\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.33187772925764186\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.29267\n",
            "Epoch 5/100\n",
            "30160/30160 [==============================] - 298s 10ms/step - loss: 0.3736 - acc: 0.8401 - val_loss: 0.2515 - val_acc: 0.9055\n",
            "0.7855695176327523\n",
            "0.7034482758620689\n",
            "— val_f1: 0.785570 — val_precision: 0.889399 — val_recall 0.703448\n",
            "F1 all\n",
            "0.7190562613430127\n",
            "***\n",
            "F1 angry: \n",
            "0.2705882352941176\n",
            "****\n",
            "F1 happy: \n",
            "0.3651452282157675\n",
            "****\n",
            "F1 others: \n",
            "0.8435341748035244\n",
            "****\n",
            "F1 sad: \n",
            "0.4636363636363635\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.32036613272311204\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.29267\n",
            "Epoch 6/100\n",
            "30160/30160 [==============================] - 295s 10ms/step - loss: 0.3681 - acc: 0.8436 - val_loss: 0.2672 - val_acc: 0.8892\n",
            "0.7492385786802032\n",
            "0.6696914700544465\n",
            "— val_f1: 0.749239 — val_precision: 0.850230 — val_recall 0.669691\n",
            "F1 all\n",
            "0.68021778584392\n",
            "***\n",
            "F1 angry: \n",
            "0.2515856236786469\n",
            "****\n",
            "F1 happy: \n",
            "0.37795275590551164\n",
            "****\n",
            "F1 others: \n",
            "0.8124383020730502\n",
            "****\n",
            "F1 sad: \n",
            "0.47286821705426346\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.3127572016460905\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.29267\n",
            "Epoch 7/100\n",
            "30160/30160 [==============================] - 299s 10ms/step - loss: 0.3671 - acc: 0.8432 - val_loss: 0.2398 - val_acc: 0.9055\n",
            "0.7876000000000001\n",
            "0.7147005444646098\n",
            "— val_f1: 0.787600 — val_precision: 0.877060 — val_recall 0.714701\n",
            "F1 all\n",
            "0.7274047186932848\n",
            "***\n",
            "F1 angry: \n",
            "0.28354430379746826\n",
            "****\n",
            "F1 happy: \n",
            "0.37229437229437223\n",
            "****\n",
            "F1 others: \n",
            "0.8465733934076357\n",
            "****\n",
            "F1 sad: \n",
            "0.47058823529411753\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.33874709976798134\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.29267\n",
            "Epoch 8/100\n",
            "30160/30160 [==============================] - 298s 10ms/step - loss: 0.3617 - acc: 0.8464 - val_loss: 0.2350 - val_acc: 0.9087\n",
            "0.8008683639234261\n",
            "0.7364791288566244\n",
            "— val_f1: 0.800868 — val_precision: 0.877595 — val_recall 0.736479\n",
            "F1 all\n",
            "0.7459165154264972\n",
            "***\n",
            "F1 angry: \n",
            "0.28571428571428564\n",
            "****\n",
            "F1 happy: \n",
            "0.37391304347826076\n",
            "****\n",
            "F1 others: \n",
            "0.8589385474860335\n",
            "****\n",
            "F1 sad: \n",
            "0.5041322314049587\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.34596375617792413\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.29267\n",
            "Epoch 9/100\n",
            "30160/30160 [==============================] - 297s 10ms/step - loss: 0.3569 - acc: 0.8477 - val_loss: 0.2452 - val_acc: 0.9003\n",
            "0.7764423076923078\n",
            "0.7034482758620689\n",
            "— val_f1: 0.776442 — val_precision: 0.866339 — val_recall 0.703448\n",
            "F1 all\n",
            "0.7150635208711432\n",
            "***\n",
            "F1 angry: \n",
            "0.2741358760429081\n",
            "****\n",
            "F1 happy: \n",
            "0.36966824644549756\n",
            "****\n",
            "F1 others: \n",
            "0.8365200764818354\n",
            "****\n",
            "F1 sad: \n",
            "0.4782608695652173\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.3318250377073905\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.29267\n",
            "Epoch 10/100\n",
            "30160/30160 [==============================] - 295s 10ms/step - loss: 0.3545 - acc: 0.8477 - val_loss: 0.2291 - val_acc: 0.9085\n",
            "0.8000787091696182\n",
            "0.7379310344827587\n",
            "— val_f1: 0.800079 — val_precision: 0.873657 — val_recall 0.737931\n",
            "F1 all\n",
            "0.7480943738656987\n",
            "***\n",
            "F1 angry: \n",
            "0.29700272479564027\n",
            "****\n",
            "F1 happy: \n",
            "0.41732283464566916\n",
            "****\n",
            "F1 others: \n",
            "0.8597475455820476\n",
            "****\n",
            "F1 sad: \n",
            "0.4918032786885244\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.36038961038961026\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.29267\n",
            "Epoch 11/100\n",
            "30160/30160 [==============================] - 299s 10ms/step - loss: 0.3533 - acc: 0.8481 - val_loss: 0.2332 - val_acc: 0.9081\n",
            "0.7988871224165343\n",
            "0.7295825771324864\n",
            "— val_f1: 0.798887 — val_precision: 0.882740 — val_recall 0.729583\n",
            "F1 all\n",
            "0.742649727767695\n",
            "***\n",
            "F1 angry: \n",
            "0.29803921568627445\n",
            "****\n",
            "F1 happy: \n",
            "0.3856502242152466\n",
            "****\n",
            "F1 others: \n",
            "0.8564727954971857\n",
            "****\n",
            "F1 sad: \n",
            "0.4883720930232557\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.3531300160513643\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.29267\n",
            "Epoch 12/100\n",
            "30160/30160 [==============================] - 296s 10ms/step - loss: 0.3487 - acc: 0.8495 - val_loss: 0.2459 - val_acc: 0.9000\n",
            "0.7793144918821406\n",
            "0.7056261343012704\n",
            "— val_f1: 0.779314 — val_precision: 0.870188 — val_recall 0.705626\n",
            "F1 all\n",
            "0.7179673321234119\n",
            "***\n",
            "F1 angry: \n",
            "0.2787286063569682\n",
            "****\n",
            "F1 happy: \n",
            "0.4275862068965515\n",
            "****\n",
            "F1 others: \n",
            "0.8362235067437378\n",
            "****\n",
            "F1 sad: \n",
            "0.5279999999999999\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.3564064801178203\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.29267\n",
            "Epoch 13/100\n",
            "30160/30160 [==============================] - 295s 10ms/step - loss: 0.3460 - acc: 0.8506 - val_loss: 0.2175 - val_acc: 0.9139\n",
            "0.8151309408341416\n",
            "0.7626134301270417\n",
            "— val_f1: 0.815131 — val_precision: 0.875417 — val_recall 0.762613\n",
            "F1 all\n",
            "0.7698729582577132\n",
            "***\n",
            "F1 angry: \n",
            "0.30654761904761896\n",
            "****\n",
            "F1 happy: \n",
            "0.4017857142857142\n",
            "****\n",
            "F1 others: \n",
            "0.8745716244002741\n",
            "****\n",
            "F1 sad: \n",
            "0.49789029535864965\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.36540158870255945\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.29267\n",
            "Epoch 14/100\n",
            "30160/30160 [==============================] - 297s 10ms/step - loss: 0.3402 - acc: 0.8527 - val_loss: 0.2283 - val_acc: 0.9082\n",
            "0.7997646597372033\n",
            "0.74010889292196\n",
            "— val_f1: 0.799765 — val_precision: 0.869881 — val_recall 0.740109\n",
            "F1 all\n",
            "0.7506352087114336\n",
            "***\n",
            "F1 angry: \n",
            "0.30705394190871366\n",
            "****\n",
            "F1 happy: \n",
            "0.442622950819672\n",
            "****\n",
            "F1 others: \n",
            "0.8584132927685465\n",
            "****\n",
            "F1 sad: \n",
            "0.511111111111111\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.3783346806790621\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.29267\n",
            "Epoch 15/100\n",
            "30160/30160 [==============================] - 294s 10ms/step - loss: 0.3375 - acc: 0.8532 - val_loss: 0.2360 - val_acc: 0.9031\n",
            "0.7895981087470448\n",
            "0.7274047186932849\n",
            "— val_f1: 0.789598 — val_precision: 0.863421 — val_recall 0.727405\n",
            "F1 all\n",
            "0.7375680580762249\n",
            "***\n",
            "F1 angry: \n",
            "0.30107526881720426\n",
            "****\n",
            "F1 happy: \n",
            "0.44363636363636355\n",
            "****\n",
            "F1 others: \n",
            "0.8487434803224276\n",
            "****\n",
            "F1 sad: \n",
            "0.5054945054945055\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.37461300309597517\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.29267\n",
            "Epoch 16/100\n",
            "30160/30160 [==============================] - 297s 10ms/step - loss: 0.3313 - acc: 0.8567 - val_loss: 0.2300 - val_acc: 0.9053\n",
            "0.7952091105438838\n",
            "0.73502722323049\n",
            "— val_f1: 0.795209 — val_precision: 0.866125 — val_recall 0.735027\n",
            "F1 all\n",
            "0.7470054446460977\n",
            "***\n",
            "F1 angry: \n",
            "0.32293080054274076\n",
            "****\n",
            "F1 happy: \n",
            "0.43410852713178283\n",
            "****\n",
            "F1 others: \n",
            "0.856403013182674\n",
            "****\n",
            "F1 sad: \n",
            "0.47940074906367025\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.37876386687797137\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.29267\n",
            "Epoch 17/100\n",
            "30160/30160 [==============================] - 296s 10ms/step - loss: 0.3290 - acc: 0.8579 - val_loss: 0.2299 - val_acc: 0.9090\n",
            "0.8015873015873016\n",
            "0.7332123411978222\n",
            "— val_f1: 0.801587 — val_precision: 0.884026 — val_recall 0.733212\n",
            "F1 all\n",
            "0.74519056261343\n",
            "***\n",
            "F1 angry: \n",
            "0.29490616621983906\n",
            "****\n",
            "F1 happy: \n",
            "0.41245136186770415\n",
            "****\n",
            "F1 others: \n",
            "0.8572099577266322\n",
            "****\n",
            "F1 sad: \n",
            "0.5220883534136546\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.3642172523961661\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.29267\n",
            "Epoch 18/100\n",
            "30160/30160 [==============================] - 295s 10ms/step - loss: 0.3265 - acc: 0.8579 - val_loss: 0.2257 - val_acc: 0.9087\n",
            "0.8043436106263332\n",
            "0.7528130671506352\n",
            "— val_f1: 0.804344 — val_precision: 0.863447 — val_recall 0.752813\n",
            "F1 all\n",
            "0.7615245009074408\n",
            "***\n",
            "F1 angry: \n",
            "0.3229629629629629\n",
            "****\n",
            "F1 happy: \n",
            "0.4571428571428571\n",
            "****\n",
            "F1 others: \n",
            "0.8653667595171772\n",
            "****\n",
            "F1 sad: \n",
            "0.49392712550607276\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.3893510815307819\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.29267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YtPqtLqdBmBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_kKdr4l-V60",
        "colab_type": "code",
        "outputId": "e2d8fc94-39fd-4292-cdbc-f43a5ce5d96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "with open(MODEL_CHECKPOINT + \".json\", \"r\") as f:\n",
        "  model = model_from_json(f.read(), custom_objects={'ElmoEmbeddingLayer':ElmoEmbeddingLayer()})\n",
        "  \n",
        "model.load_weights(MODEL_CHECKPOINT)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0405 05:43:45.993275 140035057215360 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cBXRm7E2VWZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# print(os.listdir(os.getcwd()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AcjaLZoLWglA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('3_elmo-dense-prelu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wrCgaLQRVb8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loaded_model = load_model(MODEL_CHECKPOINT, custom_objects={'ElmoEmbeddingLayer':ElmoEmbeddingLayer()})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXl141M5BNN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicts = (np.asarray(model.predict(test[CONCATENATED_TURNS][:3]))).round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5bT3G5OG0cm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(predicts[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJp29ox0BPDa",
        "colab_type": "code",
        "outputId": "b41b5766-d340-4653-b9b0-ac4a1911d61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "cell_type": "code",
      "source": [
        "print_metrics_predicted(predicts, Y_test, filename=MODEL_CHECKPOINT+\"-results\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 all\n",
            "0.6666666666666665\n",
            "***\n",
            "F1 angry: \n",
            "0.0\n",
            "****\n",
            "F1 happy: \n",
            "0.0\n",
            "****\n",
            "F1 others: \n",
            "0.7999999999999999\n",
            "****\n",
            "F1 sad: \n",
            "0.0\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "EyuJzVHIMt3n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"running\")\n",
        "predicts =\n",
        "f1 = print_metrics(model, test[CONCATENATED_TURNS], Y_test, \"3_Elmo-2epochs-results.txt\")\n",
        "print(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXJK_pAL1Myg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSaoo7V5MvdG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}