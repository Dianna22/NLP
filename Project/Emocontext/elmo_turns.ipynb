{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "elmo-turns",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "hkCLUzRJyyPn",
        "je7UaZCqzGrG",
        "nYRxedi_iJwB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dianna22/NLP/blob/master/Project/Emocontext/elmo_turns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4yNrZNr2LXw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e58f020-2d2c-4f2f-eed4-9af17f792042"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q emoji"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    24% |████████                        | 10kB 18.7MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 20kB 1.8MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 30kB 2.7MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 40kB 3.5MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 51kB 3.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cNbKcFbbWnRO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOiQzEW2Xltz",
        "colab_type": "code",
        "outputId": "59d68780-e829-448f-b296-0a71ea9c6ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fVMswhWzXlj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with open('/content/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "#   f.write('Hello Google Drive!')\n",
        "# !cat /content/gdrive/My\\ Drive/foo.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21j_GjDXJvIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "60818041-0dab-4969-db48-830f2039b26c"
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import emoji\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Add, Average, Maximum\n",
        "from keras.layers import Dropout, Input, TimeDistributed, PReLU\n",
        "from keras.models import Sequential, Model, load_model, save_model, model_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import regularizers\n",
        "from keras.utils import to_categorical\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0410 05:13:44.555818 140604992288640 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hkCLUzRJyyPn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Elmo layer"
      ]
    },
    {
      "metadata": {
        "id": "5EaTL-bkKB_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)\n",
        "\n",
        "class ElmoEmbeddingLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.dimensions = 1024\n",
        "        self.trainable=True\n",
        "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
        "                               name=\"{}_module\".format(self.name))\n",
        "\n",
        "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
        "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
        "                      as_dict=True,\n",
        "                      signature='default',\n",
        "                      )['default']\n",
        "        return result\n",
        "\n",
        "#     def compute_mask(self, inputs, mask=None):\n",
        "#         return K.not_equal(inputs, '--PAD--')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.dimensions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FOl3ocAjy1fW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Path vars & load"
      ]
    },
    {
      "metadata": {
        "id": "ulokFrhSYBAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_prefix='/content/gdrive/My Drive/NLP/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVO2OpyqKCRn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvzGGQDkKCMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_FILE = path_prefix + 'train.txt'\n",
        "DEV_FILE =  path_prefix + 'dev.txt'\n",
        "TEST_FILE =  path_prefix + 'test.txt'\n",
        "\n",
        "TURNS_NAMES = [\"turn1\", \"turn2\", \"turn3\"]\n",
        "LABEL = [\"label\"]\n",
        "CONCATENATED_TURNS = \"turns\"\n",
        "def parse_file(file_path):\n",
        "    output_dict = dict()\n",
        "    with open(file_path, newline='\\n', encoding='utf8') as csvfile:\n",
        "        return pd.read_csv(csvfile, sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vPp3GqTLpP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_CHECKPOINT = path_prefix + '3_elmo-turns'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlvvfyEcKCQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = parse_file(TRAIN_FILE)\n",
        "dev_data = parse_file(DEV_FILE)\n",
        "test_data = parse_file(TEST_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjlDYAH_Lgzp",
        "colab_type": "code",
        "outputId": "5d947a89-f012-4d0e-d36a-a34fe684c806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.shape(train_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30160, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "40M3KQQmKCWf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concatenate_turns(df, delim=\"fullstop\"):\n",
        "    turns = [(\"%s %s %s %s %s\" %\n",
        "                 (row[TURNS_NAMES[0]], delim,\n",
        "                  row[TURNS_NAMES[1]], delim,\n",
        "                  row[TURNS_NAMES[2]])).lower()\n",
        "                 for index, row in df.iterrows()]\n",
        "    df[CONCATENATED_TURNS] = pd.Series(turns, index=df.index)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ffWsWOElKCXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def emoticons_replace(df):\n",
        "    for index, row in df.iterrows():\n",
        "        for turn in range(3):\n",
        "          turns = emoji.demojize(row[TURNS_NAMES[turn]])\n",
        "          # remove delimiters \":\"  (:smiley: -> smiley)\n",
        "          for emoj in re.findall(\":\\w*:\", turns):\n",
        "              turns  = turns.replace(emoj, emoj[1:-1])\n",
        "          df.at[index, TURNS_NAMES[turn]] = turns\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DougW0jJLSr5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = emoticons_replace(train_data)\n",
        "dev = emoticons_replace(dev_data)\n",
        "test = emoticons_replace(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEnP1ua9Lljb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_sentence = [163,82,189]\n",
        "### angry: [1 0 0 0]\n",
        "### happy: [0 1 0 0]\n",
        "### others: [0 0 1 0]\n",
        "### sad: [0 0 0 1]\n",
        "labels = {0: 'angry',\n",
        "          1: 'happy',\n",
        "          2: 'others',\n",
        "          3: 'sad'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xA-W8YxHLlve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### angry: [1 0 0 0]\n",
        "### happy: [0 1 0 0]\n",
        "### others: [0 0 1 0]\n",
        "### sad: [0 0 0 1]\n",
        "Y_train = pd.get_dummies(train[LABEL]).as_matrix()\n",
        "# for i, t in enumerate(train[LABEL].iterrows()):\n",
        "#     if t[1]['label']=='others':\n",
        "#         print(Y_train[i])\n",
        "#         break\n",
        "Y_dev = pd.get_dummies(dev[LABEL]).as_matrix()\n",
        "Y_test = pd.get_dummies(test[LABEL]).as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CBY9kuH8y-72",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Model Callback"
      ]
    },
    {
      "metadata": {
        "id": "TQu-fylnLpHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Metrics(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.val_f1s = []\n",
        "        self.val_recalls = []\n",
        "        self.val_precisions = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        val_predict = (np.asarray(self.model.predict([self.validation_data[:3][i] for i in range(3)]))).round()\n",
        "        val_targ = self.validation_data[3]\n",
        "\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average='micro')\n",
        "        _val_recall = recall_score(val_targ, val_predict, average='micro')\n",
        "        _val_precision = precision_score(val_targ, val_predict, average='micro')\n",
        "\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        print(\"— val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
        "        f1 = print_metrics_predicted(val_predict, val_targ, MODEL_CHECKPOINT+\"-results\")\n",
        "        if f1 >max_f1:\n",
        "          self.model.save(MODEL_CHECKPOINT)\n",
        "        return\n",
        " \n",
        "metrics = Metrics()\n",
        "\n",
        "def print_metrics_predicted(predicts,Y,filename):\n",
        "    tp =[0,0,0,0]\n",
        "    fp =[0,0,0,0]\n",
        "    fn =[0,0,0,0]\n",
        "    for i,pred in enumerate(predicts):\n",
        "        p = np.argmax(pred)\n",
        "        y = np.argmax(Y[i])\n",
        "        if p == y:\n",
        "            tp[p] += 1\n",
        "        else:\n",
        "            fp[p] +=1\n",
        "            fn[y] +=1\n",
        "    prec = sum(tp)/(sum(tp+fp)+np.finfo(float).eps)\n",
        "    rec = sum(tp)/(sum(tp+fn)+np.finfo(float).eps)\n",
        "    with open(filename, \"w\") as f:\n",
        "      print(\"F1 all\")\n",
        "      f1_all = 2*prec*rec/(prec+rec+np.finfo(float).eps)\n",
        "      print(f1_all) \n",
        "      f.write(str(f1_all))\n",
        "      print(\"***\")\n",
        "      for i in range(4):\n",
        "          print(\"F1 %s: \" % labels[i])\n",
        "          f.write(\"\\n%s: \" % labels[i])\n",
        "          prec = tp[i]/(tp[i]+fp[i]+np.finfo(float).eps)\n",
        "          rec = tp[i]/(tp[i]+fn[i]+np.finfo(float).eps)\n",
        "          f1 = 2*prec*rec/(prec+rec+np.finfo(float).eps)\n",
        "          print(f1)\n",
        "          f.write(str(f1))\n",
        "          print(\"****\")\n",
        "      tp.pop(2)\n",
        "      fp.pop(2)\n",
        "      fn.pop(2)\n",
        "      print(\"F1 happy angry sad\")\n",
        "      f.write(\"\\nF1 happy angry sad: \")\n",
        "      prec = sum(tp)/(sum(tp+fp)+np.finfo(float).eps)\n",
        "      rec = sum(tp)/(sum(tp+fn)+np.finfo(float).eps)\n",
        "      f1= 2*prec*rec/(prec+rec+np.finfo(float).eps)\n",
        "      f.write(str(f1))\n",
        "      print(f1)\n",
        "      return f1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "je7UaZCqzGrG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Model params\n"
      ]
    },
    {
      "metadata": {
        "id": "tDGkgcupLpLD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vocabulary_size = len(tokenizer.word_counts) + 1\n",
        "\n",
        "epochs = 10\n",
        "embed_dim = 256\n",
        "lstm_out = 128\n",
        "batch_size = 128\n",
        "drop_out = 0.3\n",
        "loss_fct = 'binary_crossentropy'\n",
        "activation_fct = 'softmax'\n",
        "optimizer = \"Adam-0.01\"\n",
        "\n",
        "parameters = \"\"\"Epochs:%s\\nEmbed_dim: %s\\nLstm_out: %s\\nBatch size: %s\\nDrop_out: %s\n",
        "Loss_fct: %s\\nActivaion_fct: %s\\nOptimizer: %s\\n\n",
        "\"\"\" %(str(epochs), str(embed_dim), str(lstm_out), str(batch_size), str(drop_out), loss_fct,\n",
        "      activation_fct, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYRxedi_iJwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### Modele esuate"
      ]
    },
    {
      "metadata": {
        "id": "rkRYZPI_kZak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_layer = Input(shape=(max_sentence,), dtype='int32')\n",
        "\n",
        "# embedding_layer = Embedding(vocabulary_size,\n",
        "#                             embed_dim,\n",
        "#                             weights=[embedding_matrix],\n",
        "#                             input_length=max_sentence,\n",
        "#                             trainable=False)(input_layer)\n",
        "# bi_lstm = Bidirectional(LSTM(lstm_out))(embedding_layer)\n",
        "# dropout = Dropout(0.4)(bi_lstm)\n",
        "# dense = Dense(128,activation=activation_fct)(dropout)\n",
        "# dropout = Dropout(0.2)(dense)\n",
        "# dense = Dense(4,activation=activation_fct)(dropout)\n",
        "# adam = optimizers.Adam(lr=0.01)\n",
        "# rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n",
        "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "# model = Model(inputs=[input_layer], outputs=dense)\n",
        "# model.compile(loss = loss_fct, optimizer=adam, metrics = ['accuracy'])\n",
        "# print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozc-ywX5kftE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_layer = Input(shape=(1,), dtype=\"string\")\n",
        "# embedding = ElmoEmbeddingLayer()(input_layer)\n",
        "# # bilstm = Bidirectional(LSTM(lstm_out), input_shape=(1024,))(embedding)dr = Dropout(0.4)(embedding)\n",
        "# dropout = Dropout(0.4)(embedding)\n",
        "# dense = Dense(128,activation=activation_fct)(dropout)\n",
        "# dropout = Dropout(0.2)(dense)\n",
        "# dense = Dense(4,activation=activation_fct)(dropout)\n",
        "\n",
        "# adam = optimizers.Adam(lr=0.01)\n",
        "# rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n",
        "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "# model = Model(inputs=[input_layer], outputs=dense)\n",
        "# model.compile(loss = 'binary_crossentropy', optimizer=adam, metrics = ['accuracy'])\n",
        "# print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MwJ8c48tLpMD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_text = Input(shape=(1,), dtype=\"string\")\n",
        "# embedding = ElmoEmbeddingLayer()(input_text)\n",
        "# # bilstm = Bidirectional(LSTM(lstm_out), input_shape=(1024,))(embedding)dr = Dropout(0.4)(embedding)\n",
        "# dense = Dense(1024, activation='relu')(embedding)\n",
        "# dense = Dense(512, activation='relu')(dense)\n",
        "# dense = Dropout(0.15)(dense)\n",
        "# dense = Dense(128, activation='relu')(dense)\n",
        "# dense = Dropout(0.1)(dense)\n",
        "# pred = Dense(4, activation='softmax')(dense)\n",
        "\n",
        "# model = Model(inputs=[input_text], outputs=pred)\n",
        "# adam = optimizers.Adam(lr=0.003)\n",
        "# model.compile(loss='mean_squared_error', optimizer= adam, metrics=['accuracy'])\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ELGLsYsmiURW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Model"
      ]
    },
    {
      "metadata": {
        "id": "LrZKCTfSiX5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "d8c01cb7-1a3d-441c-dda2-d053fc9292ef"
      },
      "cell_type": "code",
      "source": [
        "input_layer1 = Input(shape=(1,), dtype=\"string\")\n",
        "embedding1 = ElmoEmbeddingLayer()(input_layer1)\n",
        "input_layer2 = Input(shape=(1,), dtype=\"string\")\n",
        "embedding2 = ElmoEmbeddingLayer()(input_layer2)\n",
        "input_layer3 = Input(shape=(1,), dtype=\"string\")\n",
        "embedding3 = ElmoEmbeddingLayer()(input_layer3)\n",
        "\n",
        "merged = Add()([embedding1, embedding2, embedding3])\n",
        "\n",
        "dropout = Dropout(0.4)(merged)\n",
        "dense = Dense(128,activation=activation_fct)(dropout)\n",
        "dropout = Dropout(0.2)(dense)\n",
        "dense = Dense(4,activation=activation_fct)(dropout)\n",
        "\n",
        "adam = optimizers.Adam(lr=0.01)\n",
        "rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=dense)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=adam, metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0410 06:41:33.276705 140604992288640 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0410 06:41:37.138902 140604992288640 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0410 06:41:41.171009 140604992288640 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_21 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "elmo_embedding_layer_19 (ElmoEm (None, 1024)         4           input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "elmo_embedding_layer_20 (ElmoEm (None, 1024)         4           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "elmo_embedding_layer_21 (ElmoEm (None, 1024)         4           input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 1024)         0           elmo_embedding_layer_19[0][0]    \n",
            "                                                                 elmo_embedding_layer_20[0][0]    \n",
            "                                                                 elmo_embedding_layer_21[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 1024)         0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 128)          131200      dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 128)          0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 4)            516         dropout_14[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 131,728\n",
            "Trainable params: 131,728\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JzWU4A2uLpGa",
        "colab_type": "code",
        "outputId": "01131e71-bc7c-4ffd-fc29-732a32693822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "max_f1 = 0\n",
        "model.fit([train[TURNS_NAMES[i]] for i in range(3)], Y_train, epochs=100, verbose=1,\n",
        "          batch_size=128,\n",
        "          validation_data=([dev[TURNS_NAMES[i]] for i in range(3)], Y_dev),\n",
        "          callbacks=[metrics,\n",
        "                     EarlyStopping(patience=5),\n",
        "                     ModelCheckpoint(MODEL_CHECKPOINT, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "                    ])\n",
        "#0.32-0.34\n",
        "#0.26-0.37\n",
        "#-droppout\n",
        "#0.37-0.40\n",
        "#+prelu\n",
        "#0.36-0.37\n",
        "#-prelu\n",
        "# 0.33-0.46\n",
        "# mse\n",
        "# 0.44 - loss 0.08 val loss 0.08\n",
        "# adam 0.03\n",
        "with open(MODEL_CHECKPOINT + \".json\",\"w\") as f:\n",
        "  f.write(model.to_json())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30160 samples, validate on 2755 samples\n",
            "Epoch 1/100\n",
            "17792/30160 [================>.............] - ETA: 2:19 - loss: 0.5172 - acc: 0.7480"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YtPqtLqdBmBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_kKdr4l-V60",
        "colab_type": "code",
        "outputId": "e2d8fc94-39fd-4292-cdbc-f43a5ce5d96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "with open(MODEL_CHECKPOINT + \".json\", \"r\") as f:\n",
        "  model = model_from_json(f.read(), custom_objects={'ElmoEmbeddingLayer':ElmoEmbeddingLayer()})\n",
        "  \n",
        "model.load_weights(MODEL_CHECKPOINT)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0405 05:43:45.993275 140035057215360 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cBXRm7E2VWZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# print(os.listdir(os.getcwd()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AcjaLZoLWglA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('3_elmo-dense-prelu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wrCgaLQRVb8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loaded_model = load_model(MODEL_CHECKPOINT, custom_objects={'ElmoEmbeddingLayer':ElmoEmbeddingLayer()})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXl141M5BNN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicts = (np.asarray(model.predict(test[CONCATENATED_TURNS][:3]))).round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5bT3G5OG0cm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(predicts[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJp29ox0BPDa",
        "colab_type": "code",
        "outputId": "b41b5766-d340-4653-b9b0-ac4a1911d61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "cell_type": "code",
      "source": [
        "print_metrics_predicted(predicts, Y_test, filename=MODEL_CHECKPOINT+\"-results\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 all\n",
            "0.6666666666666665\n",
            "***\n",
            "F1 angry: \n",
            "0.0\n",
            "****\n",
            "F1 happy: \n",
            "0.0\n",
            "****\n",
            "F1 others: \n",
            "0.7999999999999999\n",
            "****\n",
            "F1 sad: \n",
            "0.0\n",
            "****\n",
            "F1 happy angry sad\n",
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "EyuJzVHIMt3n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"running\")\n",
        "predicts =\n",
        "f1 = print_metrics(model, test[CONCATENATED_TURNS], Y_test, \"3_Elmo-2epochs-results.txt\")\n",
        "print(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXJK_pAL1Myg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSaoo7V5MvdG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}