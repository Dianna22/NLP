{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install emoji\n!pip install bert-embedding\n# !pip install mxnet-cu92\n# !pip install --upgrade numpy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# import os\n# print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport mxnet as mx\nfrom bert_embedding import BertEmbedding\n\nimport emoji\nimport re\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_prefix='../input/'\nTRAIN_FILE = path_prefix + 'train.txt'\nDEV_FILE =  path_prefix + 'dev.txt'\nTEST_FILE =  path_prefix + 'test.txt'\n\nTURNS_NAMES = [\"turn1\", \"turn2\", \"turn3\"]\nLABEL = [\"label\"]\nTURNS_CONCAT = \"turns\"\ndef parse_file(file_path):\n    output_dict = dict()\n    with open(file_path, newline='\\n', encoding='utf8') as csvfile:\n        return pd.read_csv(csvfile, sep=\"\\t\")\n\ntrain_data = parse_file(TRAIN_FILE)\ndev_data = parse_file(DEV_FILE)\ntest_data = parse_file(TEST_FILE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def concatenate_turns(df, delim=\"fullstop\"):\n    turns = [(\"%s %s %s %s %s\" %\n                 (row[TURNS_NAMES[0]], delim,\n                  row[TURNS_NAMES[1]], delim,\n                  row[TURNS_NAMES[2]])).lower()\n                 for index, row in df.iterrows()]\n    df[CONCATENATED_TURNS] = pd.Series(turns, index=df.index)\n    return df\ndef emoticons_replace(df):\n    for index, row in df.iterrows():\n        for turn in range(3):\n          turns = emoji.demojize(row[TURNS_NAMES[turn]])\n          # remove delimiters \":\"  (:smiley: -> smiley)\n          for emoj in re.findall(\":\\w*:\", turns):\n              turns  = turns.replace(emoj, emoj[1:-1])\n          df.at[index, TURNS_NAMES[turn]] = turns\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = concatenate_turns(emoticons_replace(train_data))\ndev = concatenate_turns(emoticons_replace(dev_data))\ntest = concatenate_turns(emoticons_replace(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### angry: [1 0 0 0]\n### happy: [0 1 0 0]\n### others: [0 0 1 0]\n### sad: [0 0 0 1]\nY_train = pd.get_dummies(train[LABEL]).as_matrix()\nY_dev = pd.get_dummies(dev[LABEL]).as_matrix()\nY_test = pd.get_dummies(test[LABEL]).as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ctx = mx.gpu(0)\n# bert = BertEmbedding(ctx=ctx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = [bert(train[TURNS_NAMES[i]]) for i in range(3)]\n# X_dev = [bert(dev[TURNS_NAMES[i]]) for i in range(3)]\n# X_test = [bert(test[TURNS_NAMES[i]]) for i in range(3)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bert_embedding = BertEmbedding(model='bert_12_768_12')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/\")\npd.DataFrame(X_train).to_csv('test_file')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = bert_embedding(train[TURNS_CONCAT][:2])\n# print(X_train[:2])\n# pd.DataFrame(X_train).to_csv('X_train_bert_2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[0][0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(X_train[0][0][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    input_layer = Input(shape=(max_sentence,), dtype='int32')\n\n    embedding_layer = Embedding(vocabulary_size,\n                                embed_dim,\n                                weights=[embedding_matrix],\n                                input_length=max_sentence,\n                                trainable=False)(input_layer)\n    bi_lstm = Bidirectional(LSTM(lstm_out))(embedding_layer)\n    dropout = Dropout(0.4)(bi_lstm)\n    dense = Dense(128,activation=activation_fct)(dropout)\n    dropout = Dropout(0.2)(dense)\n    dense = Dense(4,activation=activation_fct)(dropout)\n    adam = optimizers.Adam(lr=0.01)\n    rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n\n    model = Model(inputs=[input_layer], outputs=dense)\n    model.compile(loss = loss_fct, optimizer=adam, metrics = ['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = KerasClassifier(build_fn = create_model, verbose = 0)\n# param_grid = {'batch_size':[10,30, 64, 128, 256, 512, 1024] , 'epochs':[10, 50, 100]}\n# grid_search = GridSearchCV(estimator= model, param_grid = param_grid, cv = 5)\n# grid_search.fit(X_train, y_train)\n# print(grid_search.best_params_)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}