{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import emoji\n",
    "from keras import optimizers\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     from nltk.corpus import words\n",
    "# except LookupError:\n",
    "#     import nltk\n",
    "#     print(\"Downloading nltk words...\")\n",
    "#     nltk.download(\"words\")\n",
    "#     from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'data/train.txt'\n",
    "DEV_FILE = 'data/dev.txt'\n",
    "TEST_FILE = 'data/test.txt'\n",
    "\n",
    "TURNS_NAMES = [\"turn1\", \"turn2\", \"turn3\"]\n",
    "LABEL = [\"label\"]\n",
    "CONCATENATED_TURNS = \"turns\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Emoticons map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "EMOTICONS_MAP = {\n",
    "    'üòò': ' emoticon',\n",
    "    'üòç': ' happyemoticon',\n",
    "    'üòÅ': ' happyemoticon',\n",
    "    'üò≠': ' sademoticon',\n",
    "    'üòë': ' sademoticon',\n",
    "    'üòª': ' happyemoticon',\n",
    "    'üòÇ': ' happyemoticon',\n",
    "    'üëç': ' emoticon',\n",
    "    'üòÄ': ' happyemoticon',\n",
    "    ':D': ' happyemoticon',\n",
    "    'üôÇ':  ' happyemoticon',\n",
    "    '<3': ' happyemoticon',\n",
    "    'üòì' : ' sademoticon',\n",
    "    'üòí' : ' angryemoticon',\n",
    "    'üòà' : ' emoticon',\n",
    "    'üëø' : ' angryemoticon',\n",
    "    'üñë' : ' happyemoticon',\n",
    "    'üòæ' : ' emoticon',\n",
    "    'üò†' : ' angryemoticon',\n",
    "    'üëª' : ' emoticon',\n",
    "    ':(' : ' sademoticon',\n",
    "    ':)' : ' happyemoticon',\n",
    "    'xD' : ' happyemoticon',\n",
    "    'üíî' : ' sademoticon',\n",
    "    'üò•' : ' emoticon',\n",
    "    'üòû' : ' sademoticon',\n",
    "    'üò§' : ' angryemoticon',\n",
    "    'üòÉ' : ' happyemoticon',\n",
    "    'üò¶' : ' sademoticon',\n",
    "    ':3' : ' emoticon',\n",
    "    'üòº' : ' emoticon',\n",
    "    'üòè' : ' happyemoticon',\n",
    "    'üò±' : ' sademoticon',\n",
    "    'üò¨' : ' sademoticon',\n",
    "    'üôÅ' : ' sademoticon',\n",
    "    '</3' : ' sademoticon',\n",
    "    'üò∫' : ' happyemoticon',\n",
    "    'üò£' : ' angryemoticon',\n",
    "    'üò¢' : ' sademoticon',\n",
    "    'üòÜ' : ' happyemoticon',\n",
    "    'üòÑ' : ' happyemoticon',\n",
    "    'üòÖ' : ' happyemoticon',\n",
    "    ':-)' : ' happyemoticon',\n",
    "    'üòä' : ' happyemoticon',\n",
    "    'üòï' : ' sademoticon',\n",
    "    'üòΩ' : ' happyemoticon',\n",
    "    'üôÄ' : ' angryemoticon',\n",
    "    'ü§£' : ' happyemoticon',\n",
    "    'ü§ê' : ' emoticon',\n",
    "    'üò°' : ' sademoticon',\n",
    "    'üëå' : ' happyemoticon', \n",
    "    'üòÆ' : ' emoticon',\n",
    "    '‚ù§Ô∏è' : ' happyemoticon',\n",
    "    'üôÑ' : ' happyemoticon',\n",
    "    'üòø' : ' sademoticon',\n",
    "    'üòâ' : ' happyemoticon',\n",
    "    'üòã' : ' happyemoticon',\n",
    "    'üòê' : ' emoticon',\n",
    "    'üòπ' : ' happyemoticon',\n",
    "    'üò¥' : ' sademoticon',\n",
    "    'üí§' : ' emoticon',\n",
    "    'üòú' : ' happyemoticon',\n",
    "    'üòá' : ' happyemoticon',\n",
    "    'üòî' : ' sademoticon',\n",
    "    'üò©' : ' sademoticon',\n",
    "    '‚ù§' : ' happyemoticon',\n",
    "    'üò≤' : ' emoticon',\n",
    "    'üò´' : ' sademoticon',\n",
    "    'üò≥' : ' sademoticon',\n",
    "    'üò∞' : ' sademoticon',\n",
    "}\n",
    "print(len(EMOTICONS_MAP.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### print_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_model(model_summary, parameters, accuracy, file_name=\"models/experiments.txt\"):\n",
    "    with open(file_name, \"a\") as f:\n",
    "        delimiter = \"==============================================\"\n",
    "        acc_delim = \"----------------------------------------------\"\n",
    "        format_string = \"===Experiment===\\n%s\\n%s\\n%s\\n%s\\n%s\\n\"\n",
    "        f.write(format_string % (model_summary,\n",
    "                                 delimiter,\n",
    "                                 parameters,\n",
    "                                 acc_delim,\n",
    "                                 str(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "    output_dict = dict()\n",
    "    with open(file_path, newline='\\n', encoding='utf8') as csvfile:\n",
    "        return pd.read_csv(csvfile, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = parse_file(TRAIN_FILE)\n",
    "dev_data = parse_file(DEV_FILE)\n",
    "test_data = parse_file(TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_turns(df, delim=\"fullstop\"):\n",
    "    turns = [(\"%s %s %s %s %s\" %\n",
    "                 (row[TURNS_NAMES[0]], delim,\n",
    "                  row[TURNS_NAMES[1]], delim,\n",
    "                  row[TURNS_NAMES[2]])).lower()\n",
    "                 for index, row in df.iterrows()]\n",
    "    df[CONCATENATED_TURNS] = pd.Series(turns, index=df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoticons_replace(df):\n",
    "    for index, row in df.iterrows():\n",
    "        turns = emoji.demojize(row[CONCATENATED_TURNS])\n",
    "        # remove delimiters \":\"  (:smiley: -> smiley)\n",
    "        for emoj in re.findall(\":\\w*:\", turns):\n",
    "            turns  = turns.replace(emoj, emoj[1:-1])\n",
    "        df.at[index, CONCATENATED_TURNS] = turns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer()\n",
    "def tokenize_turns(df):\n",
    "    turns = [tweet_tokenizer.tokenize(row[CONCATENATED_TURNS]) \n",
    "                for idx, row in df.iterrows()]\n",
    "    df[CONCATENATED_TURNS] = pd.Series(turns, index=df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = emoticons_replace(concatenate_turns(train_data))\n",
    "dev = emoticons_replace(concatenate_turns(dev_data))\n",
    "test = emoticons_replace(concatenate_turns(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoding\n",
    "# from sklearn import preprocessing\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# print(le.fit(train[LABEL]))\n",
    "# print(le.classes_)\n",
    "# print(train[LABEL])\n",
    "# print(le.transform(train[LABEL]))\n",
    "# print(train[LABEL])\n",
    "\n",
    "# One Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence = 189 # 163,82,189\n",
    "### angry: [1 0 0 0]\n",
    "### happy: [0 1 0 0]\n",
    "### others: [0 0 1 0]\n",
    "### sad: [0 0 0 1]\n",
    "labels = {0: 'angry',\n",
    "          1: 'happy',\n",
    "          2: 'others',\n",
    "          3: 'sad'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "all_text = train[CONCATENATED_TURNS]\n",
    "all_text = all_text.append(dev[CONCATENATED_TURNS])\n",
    "all_text = all_text.append(test[CONCATENATED_TURNS])\n",
    "\n",
    "# TODO\n",
    "# alternative: fit_on_english corpora: \n",
    "# tokenizer.fit_on_texts(words.words())\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train[CONCATENATED_TURNS]),\n",
    "                        maxlen=max_sentence)\n",
    "X_dev = pad_sequences(tokenizer.texts_to_sequences(dev[CONCATENATED_TURNS]),\n",
    "                      maxlen=max_sentence)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test[CONCATENATED_TURNS]),\n",
    "                       maxlen=max_sentence)\n",
    "### angry: [1 0 0 0]\n",
    "### happy: [0 1 0 0]\n",
    "### others: [0 0 1 0]\n",
    "### sad: [0 0 0 1]\n",
    "Y_train = pd.get_dummies(train[LABEL]).as_matrix()\n",
    "# for i, t in enumerate(train[LABEL].iterrows()):\n",
    "#     if t[1]['label']=='others':\n",
    "#         print(Y_train[i])\n",
    "#         break\n",
    "Y_dev = pd.get_dummies(dev[LABEL]).as_matrix()\n",
    "Y_test = pd.get_dummies(test[LABEL]).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(tokenizer))\n",
    "\n",
    "for tok in tokenizer.word_count:\n",
    "    if tok[1] == 1:\n",
    "        print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Model eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='micro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='micro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='micro')\n",
    "        print(_val_f1)\n",
    "        print(_val_recall)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(\"‚Äî val_f1: %f ‚Äî val_precision: %f ‚Äî val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    " \n",
    "metrics = Metrics()\n",
    "\n",
    "def print_metrics(model,X,Y, file_name):\n",
    "    predicts = (np.asarray(model.predict(X))).round()\n",
    "    tp =[0,0,0,0]\n",
    "    fp =[0,0,0,0]\n",
    "    fn =[0,0,0,0]\n",
    "    for i,pred in enumerate(predicts):\n",
    "        p = np.argmax(pred)\n",
    "        y = np.argmax(Y[i])\n",
    "        if p == y:\n",
    "            tp[p] += 1\n",
    "        else:\n",
    "            fp[p] +=1\n",
    "            fn[y] +=1\n",
    "    prec = sum(tp)/sum(tp+fp)\n",
    "    rec = sum(tp)/sum(tp+fn)\n",
    "    with open(file_name, 'a') as f:\n",
    "        print(\"F1 all\", file=f)\n",
    "        print(2*prec*rec/(prec+rec), file=f) \n",
    "        print(\"***\", file=f)\n",
    "        for i in range(4):\n",
    "            print(\"F1 %s: \" % labels[i], file=f)\n",
    "            prec = tp[i]/(tp[i]+fp[i])\n",
    "            rec = tp[i]/(tp[i]+fn[i])\n",
    "            print(2*prec*rec/(prec+rec), file=f)\n",
    "            print(\"****\", file=f)\n",
    "        tp.pop(2)\n",
    "        fp.pop(2)\n",
    "        fn.pop(2)\n",
    "        print(\"F1 happy angry sad\", file=f)\n",
    "        prec = sum(tp)/sum(tp+fp)\n",
    "        rec = sum(tp)/sum(tp+fn)\n",
    "        f1= 2*prec*rec/(prec+rec)\n",
    "        print(f1, file=f)\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts) + 1\n",
    "\n",
    "epochs = 10\n",
    "embed_dim = 256\n",
    "lstm_out = 128\n",
    "batch_size = 128\n",
    "drop_out = 0.3\n",
    "loss_fct = 'binary_crossentropy'\n",
    "activation_fct = 'softmax'\n",
    "optimizer = \"Adam-0.01\"\n",
    "\n",
    "parameters = \"\"\"Epochs:%s\\nEmbed_dim: %s\\nLstm_out: %s\\nBatch size: %s\\nDrop_out: %s\n",
    "Loss_fct: %s\\nActivaion_fct: %s\\nOptimizer: %s\\n\n",
    "\"\"\" %(str(epochs), str(embed_dim), str(lstm_out), str(batch_size), str(drop_out), loss_fct,\n",
    "      activation_fct, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 189, 256)          4783104   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 5,178,372\n",
      "Trainable params: 5,178,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embed_dim,input_length = X_train.shape[1]))\n",
    "model.add(Bidirectional(LSTM(lstm_out)))\n",
    "model.add(Dropout(drop_out))\n",
    "model.add(Dense(4,activation=activation_fct))\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss = loss_fct, optimizer=adam, metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = 'models/1_emb-bilstm-dr-dense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/10\n",
      "30080/30160 [============================>.] - ETA: 2s - loss: 0.2182 - acc: 0.91610.8758747697974217\n",
      "0.8631578947368421\n",
      "‚Äî val_f1: 0.875875 ‚Äî val_precision: 0.888972 ‚Äî val_recall 0.863158\n",
      "Epoch 00000: val_acc improved from -inf to 0.93884, saving model to models/1_emb-bilstm-dr-dense\n",
      "30160/30160 [==============================] - 905s - loss: 0.2180 - acc: 0.9161 - val_loss: 0.1615 - val_acc: 0.9388\n",
      "Epoch 2/10\n",
      "30080/30160 [============================>.] - ETA: 2s - loss: 0.1296 - acc: 0.95310.8802648519404084\n",
      "0.8686025408348458\n",
      "‚Äî val_f1: 0.880265 ‚Äî val_precision: 0.892245 ‚Äî val_recall 0.868603\n",
      "Epoch 00001: val_acc improved from 0.93884 to 0.94093, saving model to models/1_emb-bilstm-dr-dense\n",
      "30160/30160 [==============================] - 980s - loss: 0.1295 - acc: 0.9531 - val_loss: 0.1610 - val_acc: 0.9409\n",
      "Epoch 3/10\n",
      "30080/30160 [============================>.] - ETA: 2s - loss: 0.1009 - acc: 0.96500.8717761112127308\n",
      "0.86497277676951\n",
      "‚Äî val_f1: 0.871776 ‚Äî val_precision: 0.878687 ‚Äî val_recall 0.864973\n",
      "Epoch 00002: val_acc did not improve\n",
      "30160/30160 [==============================] - 931s - loss: 0.1013 - acc: 0.9649 - val_loss: 0.1802 - val_acc: 0.9364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2f95d0ef0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=epochs, verbose=1, batch_size=batch_size,\n",
    "          validation_data=(X_dev, Y_dev),\n",
    "          callbacks=[metrics,\n",
    "                     EarlyStopping(),\n",
    "                     ModelCheckpoint(MODEL_CHECKPOINT, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, Y_test, callbacks=[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25542368246338765, 0.9074695951970222]\n",
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6213307240704501\n"
     ]
    }
   ],
   "source": [
    "f1 = print_metrics(model, X_test, Y_test, OPTS_PATH)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model save & load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '%s-%s.json' % (MODEL_CHECKPOINT, str(f1))\n",
    "MODEL_W_PATH = '%s-%s.h5' % (MODEL_CHECKPOINT, str(f1))\n",
    "OPTS_PATH = 'models/1_opts-emb-bilstm-dr-dense'\n",
    "with open(OPTS_PATH, 'w') as f:\n",
    "    f.write(str(model.get_config()))\n",
    "    f.write(\"\\n%s\" % parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    return load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30160, 163)\n",
      "(30160, 4)\n",
      "(2755, 82)\n",
      "(2755, 4)\n",
      "(5509, 189)\n",
      "(5509, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))\n",
    "\n",
    "print(np.shape(X_dev))\n",
    "\n",
    "print(np.shape(Y_dev))\n",
    "\n",
    "\n",
    "print(np.shape(X_test))\n",
    "\n",
    "print(np.shape(Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e6be62e4463f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(f1_score(y_true, y_pred, average='macro'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(f1_score(y_true, y_pred, average='weighted'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print(f1_score(y_true, y_pred, average='samples'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\python 36 64\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\python 36 64\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\python 36 64\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\python 36 64\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "# y_true = [[0,0,0,1], [0,1,0,0], [1,0,0,0]]\n",
    "# y_pred = [[0,0,0,1], [1,0,0,0], [1,0,0,0]]\n",
    "# # print(f1_score(y_true, y_pred, average='macro'))\n",
    "# print(f1_score(y_true, y_pred, average='micro')) \n",
    "# # print(f1_score(y_true, y_pred, average='weighted')) \n",
    "# # print(f1_score(y_true, y_pred, average='samples')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect as i\n",
    "import sys\n",
    "sys.stdout.write(i.getsource(model.evaluate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Emocontext",
   "language": "python",
   "name": "emocontext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
