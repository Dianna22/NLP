{"cells":[{"metadata":{"id":"4yNrZNr2LXw8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"097c8dcd-cce7-482f-b8c9-68723ccfca35","trusted":true},"cell_type":"code","source":"# !pip install emoji","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\na = pd.DataFrame([[1,10,3],[5,6,7]])\nmax(a.max())","execution_count":null,"outputs":[]},{"metadata":{"id":"21j_GjDXJvIR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"4ad30ce2-4ec4-450a-88a2-52e473518037","trusted":true},"cell_type":"code","source":"import csv\nimport emoji\nfrom keras import backend as K\nfrom keras import optimizers\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\nfrom keras.engine import Layer\nfrom keras.layers import Dense, Embedding, LSTM, Bidirectional, Add, Average, Maximum, Concatenate\nfrom keras.layers import Dropout, Input, TimeDistributed, PReLU\nfrom keras.models import Sequential, Model, load_model, save_model, model_from_json\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras import regularizers\nfrom keras.utils import to_categorical\nfrom nltk.tokenize import TweetTokenizer\nimport numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport time\n\nfrom matplotlib import pyplot as plt\nfrom IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"hkCLUzRJyyPn","colab_type":"text"},"cell_type":"markdown","source":"#### Elmo layer"},{"metadata":{"id":"5EaTL-bkKB_A","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)\n\nclass ElmoEmbeddingLayer(Layer):\n    def __init__(self, **kwargs):\n        self.dimensions = 1024\n        self.trainable=True\n        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n                               name=\"{}_module\".format(self.name))\n\n        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n        super(ElmoEmbeddingLayer, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n                      as_dict=True,\n                      signature='default',\n                      )['default']\n        return result\n\n#     def compute_mask(self, inputs, mask=None):\n#         return K.not_equal(inputs, '--PAD--')\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.dimensions)","execution_count":null,"outputs":[]},{"metadata":{"id":"FOl3ocAjy1fW","colab_type":"text"},"cell_type":"markdown","source":"#### Path vars & load"},{"metadata":{"id":"ulokFrhSYBAj","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"path_prefix='../input/'","execution_count":null,"outputs":[]},{"metadata":{"id":"qvzGGQDkKCMZ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"TRAIN_FILE = path_prefix + 'train.txt'\nDEV_FILE =  path_prefix + 'dev.txt'\nTEST_FILE =  path_prefix + 'test.txt'\n\nTURNS_NAMES = [\"turn1\", \"turn2\", \"turn3\"]\nLABEL = [\"label\"]\nCONCATENATED_TURNS = \"turns\"\ndef parse_file(file_path):\n    output_dict = dict()\n    with open(file_path, newline='\\n', encoding='utf8') as csvfile:\n        return pd.read_csv(csvfile, sep=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{"id":"7vPp3GqTLpP8","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"MODEL_CHECKPOINT = '3_elmo-turns'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# from subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"id":"YlvvfyEcKCQx","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train_data = parse_file(TRAIN_FILE)\ndev_data = parse_file(DEV_FILE)\ntest_data = parse_file(TEST_FILE)","execution_count":null,"outputs":[]},{"metadata":{"id":"EjlDYAH_Lgzp","colab_type":"code","outputId":"5d947a89-f012-4d0e-d36a-a34fe684c806","colab":{"base_uri":"https://localhost:8080/","height":35},"trusted":true},"cell_type":"code","source":"print(np.shape(train_data))","execution_count":null,"outputs":[]},{"metadata":{"id":"40M3KQQmKCWf","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def concatenate_turns(df, delim=\"fullstop\"):\n    turns = [(\"%s %s %s %s %s\" %\n                 (row[TURNS_NAMES[0]], delim,\n                  row[TURNS_NAMES[1]], delim,\n                  row[TURNS_NAMES[2]])).lower()\n                 for index, row in df.iterrows()]\n    df[CONCATENATED_TURNS] = pd.Series(turns, index=df.index)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"id":"ffWsWOElKCXW","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def emoticons_replace(df):\n    for index, row in df.iterrows():\n        for turn in range(3):\n          turns = emoji.demojize(row[TURNS_NAMES[turn]])\n          # remove delimiters \":\"  (:smiley: -> smiley)\n          for emoj in re.findall(\":\\w*:\", turns):\n              turns  = turns.replace(emoj, emoj[1:-1]).replace(\"_\", \" \")\n          df.at[index, TURNS_NAMES[turn]] = turns\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"DougW0jJLSr5","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train = emoticons_replace(train_data)\ndev = emoticons_replace(dev_data)\ntest = emoticons_replace(test_data)","execution_count":null,"outputs":[]},{"metadata":{"id":"NEnP1ua9Lljb","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"max_sentence = [163,82,189]\n### angry: [1 0 0 0]\n### happy: [0 1 0 0]\n### others: [0 0 1 0]\n### sad: [0 0 0 1]\nlabels = {0: 'angry',\n          1: 'happy',\n          2: 'others',\n          3: 'sad'}","execution_count":null,"outputs":[]},{"metadata":{"id":"xA-W8YxHLlve","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"### angry: [1 0 0 0]\n### happy: [0 1 0 0]\n### others: [0 0 1 0]\n### sad: [0 0 0 1]\nY_train = pd.get_dummies(train[LABEL]).as_matrix()\n# for i, t in enumerate(train[LABEL].iterrows()):\n#     if t[1]['label']=='others':\n#         print(Y_train[i])\n#         break\nY_dev = pd.get_dummies(dev[LABEL]).as_matrix()\nY_test = pd.get_dummies(test[LABEL]).as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"id":"CBY9kuH8y-72","colab_type":"text"},"cell_type":"markdown","source":"#### Model Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"TQu-fylnLpHQ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class Metrics(Callback):\n    def __init__(self, test_X, test_Y, tolerance):\n        self.test_X = test_X\n        self.test_Y = test_Y\n        self.max_f1 = 0\n        self.f1_prev = 0\n        self.tolerance = tolerance\n        self.decreasing_times = 0\n        \n        \n    def on_train_begin(self, logs={}):\n        self.val_f1s = []\n        self.val_recalls = []\n        self.val_precisions = []\n        self.i = 0\n        self.x = []\n        \n        self.f1s_test = []\n        self.f1s_val = []\n        self.losses = []\n        self.val_losses = []\n        \n        self.logs = []\n        self.fig = plt.figure()\n    \n    def plot_losses(self, f1_val,f1_test, logs):\n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.f1s_test.append(f1_test)\n        self.f1s_val.append(f1_val)\n        self.i += 1\n        \n#         clear_output(wait=True)\n        \n        plt.subplot(2,1,1)\n        plt.plot(self.x, self.losses, label=\"train_loss\")\n        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n        plt.legend()\n        plt.subplot(2,1,2)\n        plt.plot(self.x, self.f1s_val, label=\"f1_val \" + '{:.2f}'.format(max(self.f1s_val)))\n        plt.plot(self.x, self.f1s_test, label=\"f1_test \" + '{:.2f}'.format(max(self.f1s_test)))\n        \n        plt.legend(loc=0)\n\n        plt.show();\n\n    def on_epoch_end(self, epoch, logs={}):\n        val_predict = (np.asarray(self.model.predict([self.validation_data[:3][i] for i in range(3)]))).round()\n        val_targ = self.validation_data[3]\n\n        _val_f1 = f1_score(val_targ, val_predict, average='micro')\n        _val_recall = recall_score(val_targ, val_predict, average='micro')\n        _val_precision = precision_score(val_targ, val_predict, average='micro')\n\n        self.val_f1s.append(_val_f1)\n        self.val_recalls.append(_val_recall)\n        self.val_precisions.append(_val_precision)\n        print(\"— val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n        predicts = self.model.predict(self.test_X)\n        test_predict = (np.asarray(predicts)).round()\n        f1 = print_metrics_predicted(val_predict, val_targ, MODEL_CHECKPOINT+\"-results\")\n        print(\"#############\\nF1 test:\\n#############\")\n        f_test = print_metrics_predicted(test_predict, self.test_Y, MODEL_CHECKPOINT+\"-results\")\n        self.plot_losses(f1, f_test, logs)\n        if f_test > self.max_f1:\n            self.max_f1 = f_test\n            self.model.save(MODEL_CHECKPOINT)\n        if f_test < self.f1_prev:\n            self.decreasing_times += 1\n            if self.decreasing_times > self.tolerance:\n                self.model.stop_training = True\n        else:\n            self.decreasing_times = 0\n        self.f1_prev = f_test\n        return\n \n# metrics = Metrics()\n\ndef print_metrics_predicted(predicts,Y,filename):\n    tp =[0,0,0,0]\n    fp =[0,0,0,0]\n    fn =[0,0,0,0]\n    for i,pred in enumerate(predicts):\n        p = np.argmax(pred)\n        y = np.argmax(Y[i])\n        if p == y:\n            tp[p] += 1\n        else:\n            fp[p] +=1\n            fn[y] +=1\n    prec = sum(tp)/(sum(tp+fp)+np.finfo(float).eps)\n    rec = sum(tp)/(sum(tp+fn)+np.finfo(float).eps)\n    with open(filename, \"w\") as f:\n      print(\"F1 all\")\n      f1_all = 2*prec*rec/(prec+rec+np.finfo(float).eps)\n      print(f1_all) \n      f.write(str(f1_all))\n      print(\"***\")\n      for i in range(4):\n          print(\"F1 %s: \" % labels[i])\n          f.write(\"\\n%s: \" % labels[i])\n          prec = tp[i]/(tp[i]+fp[i]+np.finfo(float).eps)\n          rec = tp[i]/(tp[i]+fn[i]+np.finfo(float).eps)\n          f1 = 2*prec*rec/(prec+rec+np.finfo(float).eps)\n          print(f1)\n          f.write(str(f1))\n          print(\"****\")\n      tp.pop(2)\n      fp.pop(2)\n      fn.pop(2)\n      print(\"F1 happy angry sad\")\n      f.write(\"\\nF1 happy angry sad: \")\n      prec = sum(tp)/(sum(tp+fp)+np.finfo(float).eps)\n      rec = sum(tp)/(sum(tp+fn)+np.finfo(float).eps)\n      f1= 2*prec*rec/(prec+rec+np.finfo(float).eps)\n      f.write(str(f1))\n      print(f1)\n      return f1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"je7UaZCqzGrG","colab_type":"text"},"cell_type":"markdown","source":"##### Model params\n"},{"metadata":{"id":"tDGkgcupLpLD","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# vocabulary_size = len(tokenizer.word_counts) + 1\n\nepochs = 10\nembed_dim = 256\nlstm_out = 128\nbatch_size = 128\ndrop_out = 0.3\nloss_fct = 'binary_crossentropy'\nactivation_fct = 'softmax'\noptimizer = \"Adam-0.01\"\n\nparameters = \"\"\"Epochs:%s\\nEmbed_dim: %s\\nLstm_out: %s\\nBatch size: %s\\nDrop_out: %s\nLoss_fct: %s\\nActivaion_fct: %s\\nOptimizer: %s\\n\n\"\"\" %(str(epochs), str(embed_dim), str(lstm_out), str(batch_size), str(drop_out), loss_fct,\n      activation_fct, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"id":"nYRxedi_iJwB","colab_type":"text","_kg_hide-input":true},"cell_type":"markdown","source":"###### Modele esuate"},{"metadata":{"id":"rkRYZPI_kZak","colab_type":"code","colab":{},"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# input_layer = Input(shape=(max_sentence,), dtype='int32')\n\n# embedding_layer = Embedding(vocabulary_size,\n#                             embed_dim,\n#                             weights=[embedding_matrix],\n#                             input_length=max_sentence,\n#                             trainable=False)(input_layer)\n# bi_lstm = Bidirectional(LSTM(lstm_out))(embedding_layer)\n# dropout = Dropout(0.4)(bi_lstm)\n# dense = Dense(128,activation=activation_fct)(dropout)\n# dropout = Dropout(0.2)(dense)\n# dense = Dense(4,activation=activation_fct)(dropout)\n# adam = optimizers.Adam(lr=0.01)\n# rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n\n# model = Model(inputs=[input_layer], outputs=dense)\n# model.compile(loss = loss_fct, optimizer=adam, metrics = ['accuracy'])\n# print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"id":"ozc-ywX5kftE","colab_type":"code","colab":{},"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# input_layer = Input(shape=(1,), dtype=\"string\")\n# embedding = ElmoEmbeddingLayer()(input_layer)\n# # bilstm = Bidirectional(LSTM(lstm_out), input_shape=(1024,))(embedding)dr = Dropout(0.4)(embedding)\n# dropout = Dropout(0.4)(embedding)\n# dense = Dense(128,activation=activation_fct)(dropout)\n# dropout = Dropout(0.2)(dense)\n# dense = Dense(4,activation=activation_fct)(dropout)\n\n# adam = optimizers.Adam(lr=0.01)\n# rmsprop = optimizers.RMSprop(lr=0.005)#, rho=0.9, epsilon=None, decay=0.0)\n# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n\n# model = Model(inputs=[input_layer], outputs=dense)\n# model.compile(loss = 'binary_crossentropy', optimizer=adam, metrics = ['accuracy'])\n# print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"id":"MwJ8c48tLpMD","colab_type":"code","colab":{},"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# input_text = Input(shape=(1,), dtype=\"string\")\n# embedding = ElmoEmbeddingLayer()(input_text)\n# # bilstm = Bidirectional(LSTM(lstm_out), input_shape=(1024,))(embedding)dr = Dropout(0.4)(embedding)\n# dense = Dense(1024, activation='relu')(embedding)\n# dense = Dense(512, activation='relu')(dense)\n# dense = Dropout(0.15)(dense)\n# dense = Dense(128, activation='relu')(dense)\n# dense = Dropout(0.1)(dense)\n# pred = Dense(4, activation='softmax')(dense)\n\n# model = Model(inputs=[input_text], outputs=pred)\n# adam = optimizers.Adam(lr=0.003)\n# model.compile(loss='mean_squared_error', optimizer= adam, metrics=['accuracy'])\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"ELGLsYsmiURW","colab_type":"text"},"cell_type":"markdown","source":"##### Model"},{"metadata":{},"cell_type":"markdown","source":"#### Model architecture\n"},{"metadata":{"id":"LrZKCTfSiX5S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":946},"outputId":"c25cdd17-73f8-445a-a893-31d5b28591f1","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"input_layer1 = Input(shape=(1,), dtype=\"string\")\nembedding1 = ElmoEmbeddingLayer()(input_layer1)\ninput_layer2 = Input(shape=(1,), dtype=\"string\")\nembedding2 = ElmoEmbeddingLayer()(input_layer2)\ninput_layer3 = Input(shape=(1,), dtype=\"string\")\nembedding3 = ElmoEmbeddingLayer()(input_layer3)\n\nmerged = Average()([embedding1, embedding2, embedding3])\n\ndropout = Dropout(0.4)(merged)\n# dense = Dense(256,activation='relu',\n#                 kernel_regularizer=regularizers.l2(0.01))(dropout)\n# dropout = Dropout(0.3)(dense)\ndense = Dense(128,activation='relu',\n                kernel_regularizer=regularizers.l2(0.001))(dropout)\ndropout = Dropout(0.2)(dense)\ndense = Dense(64,activation='relu',\n                kernel_regularizer=regularizers.l2(0.0001))(dropout)\ndropout = Dropout(0.2)(dense)\ndense = Dense(4,activation='softmax')(dropout)\n\nadam = optimizers.Adam(lr=0.01)\nrmsprop = optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\nsgd = optimizers.SGD(lr=1, decay=1e-6, momentum=0.9, nesterov=True)\n\nmodel = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=dense)\nmodel.compile(loss = 'categorical_crossentropy', optimizer=rmsprop, metrics = ['accuracy'])\nprint(model.summary())\n# with open(MODEL_CHECKPOINT + \".json\",\"w\") as f:\n#   f.write(model.to_json())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_turns = train[TURNS_NAMES].T.values\n# dev_turns = dev[TURNS_NAMES].T\n# test_turns = test[TURNS_NAMES].T\n# model.predict([test[TURNS_NAMES[i]] for i in range(3)])\n# Y_test","execution_count":null,"outputs":[]},{"metadata":{"id":"JzWU4A2uLpGa","colab_type":"code","outputId":"b9549332-0f44-4ef3-c3a3-69cbe549b5ae","colab":{"base_uri":"https://localhost:8080/","height":435},"trusted":true},"cell_type":"code","source":"model.fit([train[TURNS_NAMES[i]] for i in range(3)], Y_train, epochs=100, verbose=1,\n          batch_size=256,\n          validation_data=([dev[TURNS_NAMES[i]] for i in range(3)], Y_dev),\n          callbacks= [ Metrics([test[TURNS_NAMES[i]] for i in range(3)], Y_test, 3),\n#                        ModelCheckpoint(MODEL_CHECKPOINT, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n                    ])\n# F1 test:\n# #############\n# F1 all\n# 0.882555817752768\n# ***\n# F1 angry: \n# 0.49165402124430946\n# ****\n# F1 happy: \n# 0.6054054054054052\n# ****\n# F1 others: \n# 0.939195710455764\n# ****\n# F1 sad: \n# 0.638830897703549\n# ****\n# F1 happy angry sad\n# 0.5705847607796809","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from IPython.display import SVG\n# from keras.utils.vis_utils import model_to_dot\n\n# SVG(model_to_dot(model).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{"id":"YtPqtLqdBmBN","colab_type":"code","colab":{},"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# predicts = (np.asarray(model.predict(test[TURNS_CONCAT][:3]))).round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print_metrics_predicted(predicts,test[LABEL],\"elmo1.txt\")","execution_count":null,"outputs":[]},{"metadata":{"id":"O_kKdr4l-V60","colab_type":"code","outputId":"2511cfe6-ce7d-4c5a-e4d8-aab398cba118","colab":{"base_uri":"https://localhost:8080/","height":126},"trusted":true},"cell_type":"code","source":"# with open(MODEL_CHECKPOINT + \".json\", \"r\") as f:\n#   model = model_from_json(f.read(), custom_objects={'ElmoEmbeddingLayer':ElmoEmbeddingLayer()})\n  \n# model.load_weights(MODEL_CHECKPOINT)","execution_count":null,"outputs":[]},{"metadata":{"id":"wrCgaLQRVb8H","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# loaded_model = load_model(MODEL_CHECKPOINT, custom_objects={'ElmoEmbeddingLayer':ElmoEmbeddingLayer()})","execution_count":null,"outputs":[]},{"metadata":{"id":"bXl141M5BNN9","colab_type":"code","colab":{},"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# predicts = (np.asarray(model.predict(test[CONCATENATED_TURNS][:3]))).round()","execution_count":null,"outputs":[]},{"metadata":{"id":"r5bT3G5OG0cm","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# print(predicts[:10])","execution_count":null,"outputs":[]},{"metadata":{"id":"KJp29ox0BPDa","colab_type":"code","outputId":"b41b5766-d340-4653-b9b0-ac4a1911d61a","colab":{"base_uri":"https://localhost:8080/","height":345},"trusted":true},"cell_type":"code","source":"# print_metrics_predicted(predicts, Y_test, filename=MODEL_CHECKPOINT+\"-results\")","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"elmo-turns","version":"0.3.2","provenance":[],"collapsed_sections":["nYRxedi_iJwB"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}