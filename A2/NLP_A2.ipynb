{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: F:\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tqdm\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.1.23  |                0         158 KB\n",
      "    certifi-2019.3.9           |           py36_0         156 KB\n",
      "    cryptography-2.6.1         |   py36h7a1dbc1_0         563 KB\n",
      "    kiwisolver-1.0.1           |   py36h6538335_0          61 KB\n",
      "    krb5-1.16.1                |       hc04afaa_7         819 KB\n",
      "    libcurl-7.64.0             |       h2a8f88b_2         283 KB\n",
      "    libpng-1.6.36              |       h2a8f88b_0         550 KB\n",
      "    openssl-1.1.1b             |       he774522_1         5.7 MB\n",
      "    pycurl-7.43.0.2            |   py36h7a1dbc1_0         182 KB\n",
      "    pyqt-5.9.2                 |   py36h6538335_2         4.2 MB\n",
      "    qt-5.9.7                   |   vc14h73c81de_0        92.3 MB\n",
      "    sqlite-3.27.2              |       he774522_0         941 KB\n",
      "    tk-8.6.8                   |       hfa6e2cd_0         3.8 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       109.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  kiwisolver         pkgs/main/win-64::kiwisolver-1.0.1-py36h6538335_0\n",
      "  krb5               pkgs/main/win-64::krb5-1.16.1-hc04afaa_7\n",
      "  libcurl            pkgs/main/win-64::libcurl-7.64.0-h2a8f88b_2\n",
      "  tqdm               pkgs/main/noarch::tqdm-4.31.1-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2017.08.26-h94faf87_0 --> 2019.1.23-0\n",
      "  certifi                        2017.7.27.1-py36h043bc9e_0 --> 2019.3.9-py36_0\n",
      "  cryptography                         2.0.3-py36h123decb_1 --> 2.6.1-py36h7a1dbc1_0\n",
      "  libpng                              1.6.32-vc14h5163883_3 --> 1.6.36-h2a8f88b_0\n",
      "  matplotlib                           2.1.0-py36h11b4b9c_0 --> 2.2.2-py36h153e9ff_1\n",
      "  openssl                             1.0.2l-vc14hcac20b0_2 --> 1.1.1b-he774522_1\n",
      "  pycurl                              7.43.0-py36h086bf4c_3 --> 7.43.0.2-py36h7a1dbc1_0\n",
      "  pyqt                                 5.6.0-py36hb5ed885_5 --> 5.9.2-py36h6538335_2\n",
      "  qt                                  5.6.2-vc14h6f8c307_12 --> 5.9.7-vc14h73c81de_0\n",
      "  sip                                 4.18.1-py36h9c25514_2 --> 4.19.8-py36h6538335_0\n",
      "  sqlite                              3.20.1-vc14h7ce8c62_1 --> 3.27.2-he774522_0\n",
      "  tk                                   8.6.7-vc14hb68737d_1 --> 8.6.8-hfa6e2cd_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "ca-certificates-2019 | 158 KB    |            |   0% \n",
      "ca-certificates-2019 | 158 KB    | ########## | 100% \n",
      "\n",
      "krb5-1.16.1          | 819 KB    |            |   0% \n",
      "krb5-1.16.1          | 819 KB    | ######5    |  66% \n",
      "krb5-1.16.1          | 819 KB    | #########9 |  99% \n",
      "krb5-1.16.1          | 819 KB    | ########## | 100% \n",
      "\n",
      "libcurl-7.64.0       | 283 KB    |            |   0% \n",
      "libcurl-7.64.0       | 283 KB    | ########## | 100% \n",
      "\n",
      "kiwisolver-1.0.1     | 61 KB     |            |   0% \n",
      "kiwisolver-1.0.1     | 61 KB     | ########## | 100% \n",
      "\n",
      "pyqt-5.9.2           | 4.2 MB    |            |   0% \n",
      "pyqt-5.9.2           | 4.2 MB    | #2         |  13% \n",
      "pyqt-5.9.2           | 4.2 MB    | ##8        |  28% \n",
      "pyqt-5.9.2           | 4.2 MB    | ####2      |  42% \n",
      "pyqt-5.9.2           | 4.2 MB    | #####9     |  59% \n",
      "pyqt-5.9.2           | 4.2 MB    | #######5   |  75% \n",
      "pyqt-5.9.2           | 4.2 MB    | ########7  |  88% \n",
      "pyqt-5.9.2           | 4.2 MB    | #########7 |  98% \n",
      "pyqt-5.9.2           | 4.2 MB    | ########## | 100% \n",
      "\n",
      "libpng-1.6.36        | 550 KB    |            |   0% \n",
      "libpng-1.6.36        | 550 KB    | #######9   |  79% \n",
      "libpng-1.6.36        | 550 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1b       | 5.7 MB    |            |   0% \n",
      "openssl-1.1.1b       | 5.7 MB    | 8          |   8% \n",
      "openssl-1.1.1b       | 5.7 MB    | #7         |  18% \n",
      "openssl-1.1.1b       | 5.7 MB    | ##9        |  30% \n",
      "openssl-1.1.1b       | 5.7 MB    | ####1      |  41% \n",
      "openssl-1.1.1b       | 5.7 MB    | #####      |  50% \n",
      "openssl-1.1.1b       | 5.7 MB    | ######2    |  62% \n",
      "openssl-1.1.1b       | 5.7 MB    | #######2   |  72% \n",
      "openssl-1.1.1b       | 5.7 MB    | ########1  |  82% \n",
      "openssl-1.1.1b       | 5.7 MB    | ########9  |  90% \n",
      "openssl-1.1.1b       | 5.7 MB    | #########6 |  96% \n",
      "openssl-1.1.1b       | 5.7 MB    | ########## | 100% \n",
      "\n",
      "certifi-2019.3.9     | 156 KB    |            |   0% \n",
      "certifi-2019.3.9     | 156 KB    | ########## | 100% \n",
      "\n",
      "cryptography-2.6.1   | 563 KB    |            |   0% \n",
      "cryptography-2.6.1   | 563 KB    | #9         |  19% \n",
      "cryptography-2.6.1   | 563 KB    | ########4  |  85% \n",
      "cryptography-2.6.1   | 563 KB    | ########## | 100% \n",
      "\n",
      "sqlite-3.27.2        | 941 KB    |            |   0% \n",
      "sqlite-3.27.2        | 941 KB    | ####5      |  46% \n",
      "sqlite-3.27.2        | 941 KB    | ########8  |  89% \n",
      "sqlite-3.27.2        | 941 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.8             | 3.8 MB    |            |   0% \n",
      "tk-8.6.8             | 3.8 MB    | 8          |   9% \n",
      "tk-8.6.8             | 3.8 MB    | ##6        |  27% \n",
      "tk-8.6.8             | 3.8 MB    | ####5      |  45% \n",
      "tk-8.6.8             | 3.8 MB    | #####9     |  60% \n",
      "tk-8.6.8             | 3.8 MB    | #######3   |  74% \n",
      "tk-8.6.8             | 3.8 MB    | ########5  |  86% \n",
      "tk-8.6.8             | 3.8 MB    | #########5 |  96% \n",
      "tk-8.6.8             | 3.8 MB    | ########## | 100% \n",
      "\n",
      "pycurl-7.43.0.2      | 182 KB    |            |   0% \n",
      "pycurl-7.43.0.2      | 182 KB    | ########## | 100% \n",
      "\n",
      "qt-5.9.7             | 92.3 MB   |            |   0% \n",
      "qt-5.9.7             | 92.3 MB   |            |   0% \n",
      "qt-5.9.7             | 92.3 MB   | 1          |   1% \n",
      "qt-5.9.7             | 92.3 MB   | 1          |   2% \n",
      "qt-5.9.7             | 92.3 MB   | 2          |   3% \n",
      "qt-5.9.7             | 92.3 MB   | 3          |   4% \n",
      "qt-5.9.7             | 92.3 MB   | 4          |   4% \n",
      "qt-5.9.7             | 92.3 MB   | 5          |   5% \n",
      "qt-5.9.7             | 92.3 MB   | 5          |   6% \n",
      "qt-5.9.7             | 92.3 MB   | 6          |   7% \n",
      "qt-5.9.7             | 92.3 MB   | 7          |   7% \n",
      "qt-5.9.7             | 92.3 MB   | 8          |   8% \n",
      "qt-5.9.7             | 92.3 MB   | 8          |   9% \n",
      "qt-5.9.7             | 92.3 MB   | 9          |  10% \n",
      "qt-5.9.7             | 92.3 MB   | #          |  11% \n",
      "qt-5.9.7             | 92.3 MB   | #1         |  11% \n",
      "qt-5.9.7             | 92.3 MB   | #2         |  12% \n",
      "qt-5.9.7             | 92.3 MB   | #3         |  13% \n",
      "qt-5.9.7             | 92.3 MB   | #3         |  14% \n",
      "qt-5.9.7             | 92.3 MB   | #4         |  15% \n",
      "qt-5.9.7             | 92.3 MB   | #5         |  16% \n",
      "qt-5.9.7             | 92.3 MB   | #6         |  16% \n",
      "qt-5.9.7             | 92.3 MB   | #7         |  17% \n",
      "qt-5.9.7             | 92.3 MB   | #8         |  18% \n",
      "qt-5.9.7             | 92.3 MB   | #8         |  19% \n",
      "qt-5.9.7             | 92.3 MB   | #9         |  20% \n",
      "qt-5.9.7             | 92.3 MB   | ##         |  20% \n",
      "qt-5.9.7             | 92.3 MB   | ##1        |  21% \n",
      "qt-5.9.7             | 92.3 MB   | ##1        |  22% \n",
      "qt-5.9.7             | 92.3 MB   | ##2        |  23% \n",
      "qt-5.9.7             | 92.3 MB   | ##3        |  24% \n",
      "qt-5.9.7             | 92.3 MB   | ##4        |  25% \n",
      "qt-5.9.7             | 92.3 MB   | ##5        |  26% \n",
      "qt-5.9.7             | 92.3 MB   | ##6        |  27% \n",
      "qt-5.9.7             | 92.3 MB   | ##7        |  27% \n",
      "qt-5.9.7             | 92.3 MB   | ##8        |  28% \n",
      "qt-5.9.7             | 92.3 MB   | ##9        |  29% \n",
      "qt-5.9.7             | 92.3 MB   | ###        |  30% \n",
      "qt-5.9.7             | 92.3 MB   | ###        |  31% \n",
      "qt-5.9.7             | 92.3 MB   | ###1       |  32% \n",
      "qt-5.9.7             | 92.3 MB   | ###2       |  32% \n",
      "qt-5.9.7             | 92.3 MB   | ###3       |  33% \n",
      "qt-5.9.7             | 92.3 MB   | ###3       |  34% \n",
      "qt-5.9.7             | 92.3 MB   | ###4       |  35% \n",
      "qt-5.9.7             | 92.3 MB   | ###5       |  35% \n",
      "qt-5.9.7             | 92.3 MB   | ###6       |  36% \n",
      "qt-5.9.7             | 92.3 MB   | ###6       |  37% \n",
      "qt-5.9.7             | 92.3 MB   | ###7       |  38% \n",
      "qt-5.9.7             | 92.3 MB   | ###8       |  38% \n",
      "qt-5.9.7             | 92.3 MB   | ###9       |  39% \n",
      "qt-5.9.7             | 92.3 MB   | ####       |  40% \n",
      "qt-5.9.7             | 92.3 MB   | ####       |  41% \n",
      "qt-5.9.7             | 92.3 MB   | ####1      |  42% \n",
      "qt-5.9.7             | 92.3 MB   | ####2      |  43% \n",
      "qt-5.9.7             | 92.3 MB   | ####3      |  44% \n",
      "qt-5.9.7             | 92.3 MB   | ####4      |  45% \n",
      "qt-5.9.7             | 92.3 MB   | ####5      |  45% \n",
      "qt-5.9.7             | 92.3 MB   | ####6      |  46% \n",
      "qt-5.9.7             | 92.3 MB   | ####7      |  47% \n",
      "qt-5.9.7             | 92.3 MB   | ####8      |  48% \n",
      "qt-5.9.7             | 92.3 MB   | ####8      |  49% \n",
      "qt-5.9.7             | 92.3 MB   | ####9      |  50% \n",
      "qt-5.9.7             | 92.3 MB   | #####      |  50% \n",
      "qt-5.9.7             | 92.3 MB   | #####1     |  51% \n",
      "qt-5.9.7             | 92.3 MB   | #####2     |  52% \n",
      "qt-5.9.7             | 92.3 MB   | #####2     |  53% \n",
      "qt-5.9.7             | 92.3 MB   | #####3     |  54% \n",
      "qt-5.9.7             | 92.3 MB   | #####4     |  55% \n",
      "qt-5.9.7             | 92.3 MB   | #####5     |  55% \n",
      "qt-5.9.7             | 92.3 MB   | #####6     |  56% \n",
      "qt-5.9.7             | 92.3 MB   | #####7     |  57% \n",
      "qt-5.9.7             | 92.3 MB   | #####8     |  58% \n",
      "qt-5.9.7             | 92.3 MB   | #####8     |  59% \n",
      "qt-5.9.7             | 92.3 MB   | #####9     |  60% \n",
      "qt-5.9.7             | 92.3 MB   | ######     |  61% \n",
      "qt-5.9.7             | 92.3 MB   | ######1    |  61% \n",
      "qt-5.9.7             | 92.3 MB   | ######2    |  62% \n",
      "qt-5.9.7             | 92.3 MB   | ######2    |  63% \n",
      "qt-5.9.7             | 92.3 MB   | ######3    |  64% \n",
      "qt-5.9.7             | 92.3 MB   | ######4    |  65% \n",
      "qt-5.9.7             | 92.3 MB   | ######5    |  66% \n",
      "qt-5.9.7             | 92.3 MB   | ######6    |  66% \n",
      "qt-5.9.7             | 92.3 MB   | ######7    |  67% \n",
      "qt-5.9.7             | 92.3 MB   | ######8    |  68% \n",
      "qt-5.9.7             | 92.3 MB   | ######8    |  69% \n",
      "qt-5.9.7             | 92.3 MB   | ######9    |  70% \n",
      "qt-5.9.7             | 92.3 MB   | #######    |  71% \n",
      "qt-5.9.7             | 92.3 MB   | #######1   |  71% \n",
      "qt-5.9.7             | 92.3 MB   | #######2   |  72% \n",
      "qt-5.9.7             | 92.3 MB   | #######2   |  73% \n",
      "qt-5.9.7             | 92.3 MB   | #######3   |  74% \n",
      "qt-5.9.7             | 92.3 MB   | #######4   |  74% \n",
      "qt-5.9.7             | 92.3 MB   | #######5   |  75% \n",
      "qt-5.9.7             | 92.3 MB   | #######5   |  76% \n",
      "qt-5.9.7             | 92.3 MB   | #######6   |  76% \n",
      "qt-5.9.7             | 92.3 MB   | #######6   |  77% \n",
      "qt-5.9.7             | 92.3 MB   | #######6   |  77% \n",
      "qt-5.9.7             | 92.3 MB   | #######7   |  77% \n",
      "qt-5.9.7             | 92.3 MB   | #######7   |  77% \n",
      "qt-5.9.7             | 92.3 MB   | #######7   |  78% \n",
      "qt-5.9.7             | 92.3 MB   | #######7   |  78% \n",
      "qt-5.9.7             | 92.3 MB   | #######8   |  78% \n",
      "qt-5.9.7             | 92.3 MB   | #######8   |  78% \n",
      "qt-5.9.7             | 92.3 MB   | #######8   |  79% \n",
      "qt-5.9.7             | 92.3 MB   | #######9   |  79% \n",
      "qt-5.9.7             | 92.3 MB   | #######9   |  79% \n",
      "qt-5.9.7             | 92.3 MB   | #######9   |  80% \n",
      "qt-5.9.7             | 92.3 MB   | #######9   |  80% \n",
      "qt-5.9.7             | 92.3 MB   | ########   |  80% \n",
      "qt-5.9.7             | 92.3 MB   | ########   |  81% \n",
      "qt-5.9.7             | 92.3 MB   | ########   |  81% \n",
      "qt-5.9.7             | 92.3 MB   | ########1  |  81% \n",
      "qt-5.9.7             | 92.3 MB   | ########1  |  81% \n",
      "qt-5.9.7             | 92.3 MB   | ########1  |  82% \n",
      "qt-5.9.7             | 92.3 MB   | ########1  |  82% \n",
      "qt-5.9.7             | 92.3 MB   | ########2  |  82% \n",
      "qt-5.9.7             | 92.3 MB   | ########2  |  83% \n",
      "qt-5.9.7             | 92.3 MB   | ########2  |  83% \n",
      "qt-5.9.7             | 92.3 MB   | ########3  |  83% \n",
      "qt-5.9.7             | 92.3 MB   | ########3  |  84% \n",
      "qt-5.9.7             | 92.3 MB   | ########3  |  84% \n",
      "qt-5.9.7             | 92.3 MB   | ########4  |  84% \n",
      "qt-5.9.7             | 92.3 MB   | ########4  |  85% \n",
      "qt-5.9.7             | 92.3 MB   | ########4  |  85% \n",
      "qt-5.9.7             | 92.3 MB   | ########5  |  85% \n",
      "qt-5.9.7             | 92.3 MB   | ########5  |  85% \n",
      "qt-5.9.7             | 92.3 MB   | ########5  |  86% \n",
      "qt-5.9.7             | 92.3 MB   | ########5  |  86% \n",
      "qt-5.9.7             | 92.3 MB   | ########6  |  86% \n",
      "qt-5.9.7             | 92.3 MB   | ########6  |  87% \n",
      "qt-5.9.7             | 92.3 MB   | ########6  |  87% \n",
      "qt-5.9.7             | 92.3 MB   | ########7  |  87% \n",
      "qt-5.9.7             | 92.3 MB   | ########7  |  87% \n",
      "qt-5.9.7             | 92.3 MB   | ########7  |  88% \n",
      "qt-5.9.7             | 92.3 MB   | ########7  |  88% \n",
      "qt-5.9.7             | 92.3 MB   | ########8  |  88% \n",
      "qt-5.9.7             | 92.3 MB   | ########8  |  89% \n",
      "qt-5.9.7             | 92.3 MB   | ########8  |  89% \n",
      "qt-5.9.7             | 92.3 MB   | ########9  |  89% \n",
      "qt-5.9.7             | 92.3 MB   | ########9  |  89% \n",
      "qt-5.9.7             | 92.3 MB   | ########9  |  90% \n",
      "qt-5.9.7             | 92.3 MB   | ########9  |  90% \n",
      "qt-5.9.7             | 92.3 MB   | #########  |  90% \n",
      "qt-5.9.7             | 92.3 MB   | #########  |  91% \n",
      "qt-5.9.7             | 92.3 MB   | #########  |  91% \n",
      "qt-5.9.7             | 92.3 MB   | #########1 |  91% \n",
      "qt-5.9.7             | 92.3 MB   | #########1 |  91% \n",
      "qt-5.9.7             | 92.3 MB   | #########1 |  92% \n",
      "qt-5.9.7             | 92.3 MB   | #########1 |  92% \n",
      "qt-5.9.7             | 92.3 MB   | #########2 |  92% \n",
      "qt-5.9.7             | 92.3 MB   | #########2 |  92% \n",
      "qt-5.9.7             | 92.3 MB   | #########2 |  93% \n",
      "qt-5.9.7             | 92.3 MB   | #########3 |  93% \n",
      "qt-5.9.7             | 92.3 MB   | #########3 |  93% \n",
      "qt-5.9.7             | 92.3 MB   | #########3 |  94% \n",
      "qt-5.9.7             | 92.3 MB   | #########4 |  94% \n",
      "qt-5.9.7             | 92.3 MB   | #########4 |  94% \n",
      "qt-5.9.7             | 92.3 MB   | #########4 |  95% \n",
      "qt-5.9.7             | 92.3 MB   | #########4 |  95% \n",
      "qt-5.9.7             | 92.3 MB   | #########5 |  95% \n",
      "qt-5.9.7             | 92.3 MB   | #########5 |  95% \n",
      "qt-5.9.7             | 92.3 MB   | #########5 |  95% \n",
      "qt-5.9.7             | 92.3 MB   | #########5 |  96% \n",
      "qt-5.9.7             | 92.3 MB   | #########5 |  96% \n",
      "qt-5.9.7             | 92.3 MB   | #########6 |  96% \n",
      "qt-5.9.7             | 92.3 MB   | #########6 |  96% \n",
      "qt-5.9.7             | 92.3 MB   | #########6 |  97% \n",
      "qt-5.9.7             | 92.3 MB   | #########7 |  97% \n",
      "qt-5.9.7             | 92.3 MB   | #########7 |  97% \n",
      "qt-5.9.7             | 92.3 MB   | #########7 |  98% \n",
      "qt-5.9.7             | 92.3 MB   | #########7 |  98% \n",
      "qt-5.9.7             | 92.3 MB   | #########8 |  98% \n",
      "qt-5.9.7             | 92.3 MB   | #########8 |  99% \n",
      "qt-5.9.7             | 92.3 MB   | #########8 |  99% \n",
      "qt-5.9.7             | 92.3 MB   | #########9 |  99% \n",
      "qt-5.9.7             | 92.3 MB   | #########9 |  99% \n",
      "qt-5.9.7             | 92.3 MB   | #########9 | 100% \n",
      "qt-5.9.7             | 92.3 MB   | #########9 | 100% \n",
      "qt-5.9.7             | 92.3 MB   | #########9 | 100% \n",
      "qt-5.9.7             | 92.3 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} tqdm\n",
    "!conda install --yes --prefix {sys.prefix} tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Glove word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_zip_file = \"glove.6B.zip\"\n",
    "glove_vectors_file = \"glove.6B.50d.txt\"\n",
    "import zipfile, urllib.request, shutil, os\n",
    "    \n",
    "#large file - 862 MB\n",
    "if (not os.path.isfile(glove_zip_file) and\n",
    "    not os.path.isfile(glove_vectors_file)):\n",
    "    with urllib.request.urlopen(\"http://nlp.stanford.edu/data/glove.6B.zip\") as response, open(glove_zip_file, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "    \"\"\"\n",
    "        If the outFile is already created, don't recreate\n",
    "        If the outFile does not exist, create it from the zipFile\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return\n",
    "\n",
    "unzip_single_file(glove_zip_file, glove_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_wordmap = {}\n",
    "with open(glove_vectors_file, \"r\", encoding=\"utf8\") as glove:\n",
    "    for line in glove:\n",
    "        name, vector = tuple(line.split(\" \", 1))\n",
    "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence2sequence(sentence):\n",
    "    \"\"\"\n",
    "     \n",
    "    - Turns an input sentence into an (n,d) matrix, \n",
    "        where n is the number of tokens in the sentence\n",
    "        and d is the number of dimensions each word vector has.\n",
    "    \n",
    "      Tensorflow doesn't need to be used here, as simply\n",
    "      turning the sentence into a sequence based off our \n",
    "      mapping does not need the computational power that\n",
    "      Tensorflow provides. Normal Python suffices for this task.\n",
    "    \"\"\"\n",
    "    tokens = sentence.lower().split(\" \")\n",
    "    rows = []\n",
    "    words = []\n",
    "    #Greedy search for tokens\n",
    "    for token in tokens:\n",
    "        i = len(token)\n",
    "        while len(token) > 0 and i > 0:\n",
    "            word = token[:i]\n",
    "            if word in glove_wordmap:\n",
    "                rows.append(glove_wordmap[word])\n",
    "                words.append(word)\n",
    "                token = token[i:]\n",
    "                i = len(token)\n",
    "            else:\n",
    "                i = i-1\n",
    "    return rows, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFeUAb2ZWUf8fFE7QkIne2f0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWcU50JuZVZwDvZlZxTnQm5lV3P8HUZAkzQS1u/EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize(sentence):\n",
    "    rows, words = sentence2sequence(sentence)\n",
    "    mat = np.vstack(rows)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    shown = ax.matshow(mat, aspect=\"auto\")\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    fig.colorbar(shown)\n",
    "    \n",
    "    ax.set_yticklabels([\"\"]+words)\n",
    "    plt.show()\n",
    "    \n",
    "visualize(\"The quick brown fox jumped over the lazy dog.\")\n",
    "visualize(\"The pretty flowers shone in the sunlight.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constants setup\n",
    "max_hypothesis_length, max_evidence_length = 30, 30\n",
    "batch_size, vector_size, hidden_size = 128, 50, 64\n",
    "\n",
    "lstm_size = hidden_size\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "input_p, output_p = 0.5, 0.5\n",
    "\n",
    "training_iterations_count = 100000\n",
    "\n",
    "display_step = 10\n",
    "\n",
    "def score_setup(row):\n",
    "    convert_dict = {\n",
    "      'ENTAILMENT': 0,\n",
    "      'NEUTRAL': 1,\n",
    "      'CONTRADICTION': 2\n",
    "    }\n",
    "    score = np.zeros((3,))\n",
    "    tag = row[\"entailment_judgment\"]\n",
    "    score[convert_dict[tag]] += 1\n",
    "    return score\n",
    "\n",
    "def fit_to_size(matrix, shape):\n",
    "    res = np.zeros(shape)\n",
    "    slices = [slice(0,min(dim,shape[e])) for e, dim in enumerate(matrix.shape)]\n",
    "    res[slices] = matrix[slices]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Training data](http://www.site.uottawa.ca/~diana/csi5386/A2_2019/SICK_train.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_data_into_scores():\n",
    "    import csv\n",
    "    with open(\"training.txt\",\"r\") as data:\n",
    "        train = csv.DictReader(data , delimiter='\\t')\n",
    "        evi_sentences = []\n",
    "        hyp_sentences = []\n",
    "        labels = []\n",
    "        scores = []\n",
    "        count = 1\n",
    "        for row in train:\n",
    "            hyp_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence_A\"].lower())[0]))\n",
    "            evi_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence_B\"].lower())[0]))\n",
    "            labels.append(row[\"entailment_judgment\"])\n",
    "            scores.append(score_setup(row))\n",
    "        \n",
    "        hyp_sentences = np.stack([fit_to_size(x, (max_hypothesis_length, vector_size))\n",
    "                          for x in hyp_sentences])\n",
    "        evi_sentences = np.stack([fit_to_size(x, (max_evidence_length, vector_size))\n",
    "                          for x in evi_sentences])\n",
    "                                 \n",
    "        return (hyp_sentences, evi_sentences), labels, np.array(scores)\n",
    "data_feature_list, correct_values, correct_scores = split_data_into_scores()\n",
    "\n",
    "l_h, l_e = max_hypothesis_length, max_evidence_length\n",
    "N, D, H = batch_size, vector_size, hidden_size\n",
    "l_seq = l_h + l_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "lstm_drop =  tf.contrib.rnn.DropoutWrapper(lstm, input_p, output_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N: The number of elements in each of our batches, \n",
    "#   which we use to train subsets of data for efficiency's sake.\n",
    "# l_h: The maximum length of a hypothesis, or the second sentence.  This is\n",
    "#   used because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# l_e: The maximum length of evidence, the first sentence.  This is used\n",
    "#   because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# D: The size of our used GloVe or other vectors.\n",
    "hyp = tf.placeholder(tf.float32, [N, l_h, D], 'hypothesis')\n",
    "evi = tf.placeholder(tf.float32, [N, l_e, D], 'evidence')\n",
    "y = tf.placeholder(tf.float32, [N, 3], 'label')\n",
    "# hyp: Where the hypotheses will be stored during training.\n",
    "# evi: Where the evidences will be stored during training.\n",
    "# y: Where correct scores will be stored during training.\n",
    "\n",
    "# lstm_size: the size of the gates in the LSTM, \n",
    "#    as in the first LSTM layer's initialization.\n",
    "lstm_back = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# lstm_back:  The LSTM used for looking backwards \n",
    "#   through the sentences, similar to lstm.\n",
    "\n",
    "# input_p: the probability that inputs to the LSTM will be retained at each\n",
    "#   iteration of dropout.\n",
    "# output_p: the probability that outputs from the LSTM will be retained at \n",
    "#   each iteration of dropout.\n",
    "lstm_drop_back = tf.contrib.rnn.DropoutWrapper(lstm_back, input_p, output_p)\n",
    "# lstm_drop_back:  A dropout wrapper for lstm_back, like lstm_drop.\n",
    "\n",
    "\n",
    "fc_initializer = tf.random_normal_initializer(stddev=0.1) \n",
    "# fc_initializer: initial values for the fully connected layer's weights.\n",
    "# hidden_size: the size of the outputs from each lstm layer.  \n",
    "#   Multiplied by 2 to account for the two LSTMs.\n",
    "fc_weight = tf.get_variable('fc_weight', [2*hidden_size, 3], \n",
    "                            initializer = fc_initializer)\n",
    "# fc_weight: Storage for the fully connected layer's weights.\n",
    "fc_bias = tf.get_variable('bias', [3])\n",
    "# fc_bias: Storage for the fully connected layer's bias.\n",
    "\n",
    "# tf.GraphKeys.REGULARIZATION_LOSSES:  A key to a collection in the graph\n",
    "#   designated for losses due to regularization.\n",
    "#   In this case, this portion of loss is regularization on the weights\n",
    "#   for the fully connected layer.\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, \n",
    "                     tf.nn.l2_loss(fc_weight)) \n",
    "\n",
    "x = tf.concat([hyp, evi], 1) # N, (Lh+Le), d\n",
    "# Permuting batch_size and n_steps\n",
    "x = tf.transpose(x, [1, 0, 2]) # (Le+Lh), N, d\n",
    "# Reshaping to (n_steps*batch_size, n_input)\n",
    "x = tf.reshape(x, [-1, vector_size]) # (Le+Lh)*N, d\n",
    "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "x = tf.split(x, l_seq,)\n",
    "\n",
    "# x: the inputs to the bidirectional_rnn\n",
    "\n",
    "\n",
    "# tf.contrib.rnn.static_bidirectional_rnn: Runs the input through\n",
    "#   two recurrent networks, one that runs the inputs forward and one\n",
    "#   that runs the inputs in reversed order, combining the outputs.\n",
    "rnn_outputs, _, _ = tf.contrib.rnn.static_bidirectional_rnn(lstm, lstm_back,\n",
    "                                                            x, dtype=tf.float32)\n",
    "# rnn_outputs: the list of LSTM outputs, as a list. \n",
    "#   What we want is the latest output, rnn_outputs[-1]\n",
    "\n",
    "classification_scores = tf.matmul(rnn_outputs[-1], fc_weight) + fc_bias\n",
    "# The scores are relative certainties for how likely the output matches\n",
    "#   a certain entailment: \n",
    "#     0: Positive entailment\n",
    "#     1: Neutral entailment\n",
    "#     2: Negative entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('Accuracy'):\n",
    "    predicts = tf.cast(tf.argmax(classification_scores, 1), 'int32')\n",
    "    y_label = tf.cast(tf.argmax(y, 1), 'int32')\n",
    "    corrects = tf.equal(predicts, y_label)\n",
    "    num_corrects = tf.reduce_sum(tf.cast(corrects, tf.float32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\n",
    "\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits = classification_scores, labels = y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    total_loss = loss + weight_decay * tf.add_n(\n",
    "        tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "opt_op = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                   | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0.0, Minibatch Loss= 1.047516, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                        | 1/782 [00:05<1:17:30,  5.95s/it]\n",
      "  0%|                                                                                                                                                                          | 3/782 [00:06<54:18,  4.18s/it]\n",
      "  1%|                                                                                                                                                                         | 7/782 [00:06<37:56,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10.0, Minibatch Loss= 1.006760, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|                                                                                                                                                                       | 11/782 [00:06<26:32,  2.07s/it]\n",
      "  2%|                                                                                                                                                                      | 15/782 [00:06<18:35,  1.45s/it]\n",
      "  2%|                                                                                                                                                                     | 19/782 [00:06<13:02,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20.0, Minibatch Loss= 0.995709, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|                                                                                                                                                                     | 22/782 [00:06<09:14,  1.37it/s]\n",
      "  3%|                                                                                                                                                                    | 26/782 [00:06<06:32,  1.93it/s]\n",
      "  4%|                                                                                                                                                                   | 30/782 [00:06<04:39,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30.0, Minibatch Loss= 0.948813, Training Accuracy= 0.58594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|                                                                                                                                                                  | 34/782 [00:06<03:22,  3.70it/s]\n",
      "  5%|                                                                                                                                                                 | 38/782 [00:07<02:26,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40.0, Minibatch Loss= 0.950432, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|                                                                                                                                                                | 42/782 [00:07<01:51,  6.63it/s]\n",
      "  6%|                                                                                                                                                                | 46/782 [00:07<01:24,  8.67it/s]\n",
      "  6%|                                                                                                                                                               | 50/782 [00:07<01:05, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50.0, Minibatch Loss= 0.946411, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|                                                                                                                                                              | 54/782 [00:07<00:53, 13.60it/s]\n",
      "  7%|                                                                                                                                                             | 58/782 [00:07<00:43, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60.0, Minibatch Loss= 0.929457, Training Accuracy= 0.60938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|                                                                                                                                                            | 62/782 [00:07<00:38, 18.56it/s]\n",
      "  8%|                                                                                                                                                           | 66/782 [00:08<00:33, 21.48it/s]\n",
      "  9%|                                                                                                                                                          | 70/782 [00:08<00:29, 24.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 70.0, Minibatch Loss= 0.933264, Training Accuracy= 0.61719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|                                                                                                                                                          | 74/782 [00:08<00:33, 21.23it/s]\n",
      " 10%|                                                                                                                                                         | 78/782 [00:08<00:29, 23.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80.0, Minibatch Loss= 1.051194, Training Accuracy= 0.44531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|                                                                                                                                                        | 81/782 [00:08<00:29, 23.53it/s]\n",
      " 11%|                                                                                                                                                       | 85/782 [00:08<00:26, 25.91it/s]\n",
      " 11%|                                                                                                                                                      | 89/782 [00:08<00:24, 27.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 90.0, Minibatch Loss= 0.918972, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|                                                                                                                                                     | 93/782 [00:09<00:25, 27.10it/s]\n",
      " 12%|                                                                                                                                                     | 97/782 [00:09<00:23, 28.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100.0, Minibatch Loss= 0.991769, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|                                                                                                                                                   | 101/782 [00:09<00:24, 28.02it/s]\n",
      " 13%|                                                                                                                                                  | 105/782 [00:09<00:23, 29.24it/s]\n",
      " 14%|                                                                                                                                                 | 109/782 [00:09<00:21, 30.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 110.0, Minibatch Loss= 1.035804, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|                                                                                                                                                | 113/782 [00:09<00:22, 30.38it/s]\n",
      " 15%|                                                                                                                                               | 117/782 [00:09<00:21, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120.0, Minibatch Loss= 0.899451, Training Accuracy= 0.58594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|                                                                                                                                              | 121/782 [00:09<00:23, 28.58it/s]\n",
      " 16%|                                                                                                                                              | 125/782 [00:10<00:21, 30.34it/s]\n",
      " 16%|                                                                                                                                             | 129/782 [00:10<00:20, 31.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 130.0, Minibatch Loss= 0.970988, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|                                                                                                                                            | 133/782 [00:10<00:20, 31.15it/s]\n",
      " 18%|                                                                                                                                           | 137/782 [00:10<00:19, 32.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140.0, Minibatch Loss= 0.968313, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|                                                                                                                                          | 141/782 [00:10<00:20, 31.24it/s]\n",
      " 19%|                                                                                                                                         | 145/782 [00:10<00:21, 30.25it/s]\n",
      " 19%|                                                                                                                                        | 149/782 [00:10<00:20, 31.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150.0, Minibatch Loss= 0.929391, Training Accuracy= 0.60938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|                                                                                                                                        | 153/782 [00:11<00:21, 29.45it/s]\n",
      " 20%|                                                                                                                                       | 157/782 [00:11<00:20, 30.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160.0, Minibatch Loss= 0.989138, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|                                                                                                                                      | 161/782 [00:11<00:21, 29.06it/s]\n",
      " 21%|                                                                                                                                     | 164/782 [00:11<00:21, 28.92it/s]\n",
      " 21%|                                                                                                                                     | 167/782 [00:11<00:21, 28.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 170.0, Minibatch Loss= 0.973588, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|                                                                                                                                    | 171/782 [00:11<00:21, 27.84it/s]\n",
      " 22%|                                                                                                                                   | 175/782 [00:11<00:20, 29.62it/s]\n",
      " 23%|                                                                                                                                  | 179/782 [00:11<00:19, 30.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180.0, Minibatch Loss= 0.951481, Training Accuracy= 0.58594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|                                                                                                                                 | 183/782 [00:12<00:19, 30.45it/s]\n",
      " 24%|                                                                                                                                | 187/782 [00:12<00:18, 32.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 190.0, Minibatch Loss= 1.005642, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|                                                                                                                               | 191/782 [00:12<00:18, 31.29it/s]\n",
      " 25%|                                                                                                                              | 195/782 [00:12<00:17, 32.82it/s]\n",
      " 25%|                                                                                                                              | 199/782 [00:12<00:17, 33.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200.0, Minibatch Loss= 0.959963, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|                                                                                                                             | 203/782 [00:12<00:17, 32.36it/s]\n",
      " 26%|                                                                                                                            | 207/782 [00:12<00:18, 31.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 210.0, Minibatch Loss= 0.986575, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|                                                                                                                           | 211/782 [00:12<00:18, 30.92it/s]\n",
      " 27%|                                                                                                                          | 215/782 [00:13<00:17, 31.99it/s]\n",
      " 28%|                                                                                                                         | 219/782 [00:13<00:16, 33.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220.0, Minibatch Loss= 0.973009, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|                                                                                                                        | 223/782 [00:13<00:18, 30.42it/s]\n",
      " 29%|                                                                                                                        | 227/782 [00:13<00:17, 31.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 230.0, Minibatch Loss= 0.962127, Training Accuracy= 0.58594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|                                                                                                                       | 231/782 [00:13<00:17, 31.10it/s]\n",
      " 30%|                                                                                                                      | 235/782 [00:13<00:16, 32.51it/s]\n",
      " 31%|                                                                                                                     | 239/782 [00:13<00:16, 33.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240.0, Minibatch Loss= 0.910340, Training Accuracy= 0.61719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|                                                                                                                    | 243/782 [00:13<00:17, 31.01it/s]\n",
      " 32%|                                                                                                                   | 247/782 [00:14<00:16, 31.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 250.0, Minibatch Loss= 0.993861, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|                                                                                                                  | 251/782 [00:14<00:17, 30.75it/s]\n",
      " 33%|                                                                                                                  | 255/782 [00:14<00:16, 31.34it/s]\n",
      " 33%|                                                                                                                 | 259/782 [00:14<00:15, 32.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260.0, Minibatch Loss= 0.903926, Training Accuracy= 0.62500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|                                                                                                                | 263/782 [00:14<00:16, 31.76it/s]\n",
      " 34%|                                                                                                               | 267/782 [00:14<00:19, 26.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 270.0, Minibatch Loss= 0.913727, Training Accuracy= 0.61719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|                                                                                                              | 271/782 [00:14<00:19, 26.71it/s]\n",
      " 35%|                                                                                                             | 275/782 [00:14<00:17, 28.83it/s]\n",
      " 36%|                                                                                                            | 279/782 [00:15<00:16, 30.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280.0, Minibatch Loss= 0.967694, Training Accuracy= 0.57812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|                                                                                                           | 283/782 [00:15<00:16, 29.92it/s]\n",
      " 37%|                                                                                                           | 287/782 [00:15<00:15, 31.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 290.0, Minibatch Loss= 1.008206, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|                                                                                                          | 291/782 [00:15<00:16, 29.63it/s]\n",
      " 38%|                                                                                                         | 295/782 [00:15<00:16, 30.03it/s]\n",
      " 38%|                                                                                                        | 299/782 [00:15<00:15, 30.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300.0, Minibatch Loss= 0.972587, Training Accuracy= 0.57031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|                                                                                                       | 303/782 [00:15<00:15, 30.15it/s]\n",
      " 39%|                                                                                                      | 307/782 [00:16<00:15, 31.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310.0, Minibatch Loss= 0.915307, Training Accuracy= 0.60938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|                                                                                                     | 311/782 [00:16<00:15, 30.61it/s]\n",
      " 40%|                                                                                                     | 315/782 [00:16<00:14, 32.06it/s]\n",
      " 41%|                                                                                                    | 319/782 [00:16<00:13, 33.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320.0, Minibatch Loss= 0.978912, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|                                                                                                   | 323/782 [00:16<00:14, 31.14it/s]\n",
      " 42%|                                                                                                  | 327/782 [00:16<00:14, 32.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 330.0, Minibatch Loss= 0.898488, Training Accuracy= 0.60156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|                                                                                                 | 331/782 [00:16<00:14, 30.39it/s]\n",
      " 43%|                                                                                                | 335/782 [00:16<00:14, 31.82it/s]\n",
      " 43%|                                                                                               | 339/782 [00:17<00:13, 32.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340.0, Minibatch Loss= 0.889181, Training Accuracy= 0.62500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|                                                                                              | 343/782 [00:17<00:14, 30.18it/s]\n",
      " 44%|                                                                                              | 347/782 [00:17<00:13, 31.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 350.0, Minibatch Loss= 0.927509, Training Accuracy= 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|                                                                                             | 351/782 [00:17<00:14, 29.76it/s]\n",
      " 45%|                                                                                            | 355/782 [00:17<00:13, 31.55it/s]\n",
      " 46%|                                                                                           | 359/782 [00:17<00:13, 32.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360.0, Minibatch Loss= 0.990789, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|                                                                                          | 363/782 [00:17<00:13, 31.20it/s]\n",
      " 47%|                                                                                         | 367/782 [00:17<00:12, 32.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 370.0, Minibatch Loss= 0.945639, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|                                                                                        | 371/782 [00:18<00:12, 31.69it/s]\n",
      " 48%|                                                                                        | 375/782 [00:18<00:12, 31.94it/s]\n",
      " 48%|                                                                                       | 379/782 [00:18<00:12, 32.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380.0, Minibatch Loss= 0.898475, Training Accuracy= 0.60156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|                                                                                      | 383/782 [00:18<00:13, 29.31it/s]\n",
      " 49%|                                                                                     | 387/782 [00:18<00:12, 30.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 390.0, Minibatch Loss= 0.960759, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|                                                                                    | 391/782 [00:18<00:13, 29.65it/s]\n",
      " 51%|                                                                                   | 395/782 [00:18<00:12, 31.09it/s]\n",
      " 51%|                                                                                  | 399/782 [00:18<00:11, 32.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400.0, Minibatch Loss= 0.964344, Training Accuracy= 0.57812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|                                                                                  | 403/782 [00:19<00:12, 31.44it/s]\n",
      " 52%|                                                                                 | 407/782 [00:19<00:12, 30.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 410.0, Minibatch Loss= 0.970889, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|                                                                                | 411/782 [00:19<00:13, 28.49it/s]\n",
      " 53%|                                                                               | 415/782 [00:19<00:12, 29.53it/s]\n",
      " 54%|                                                                              | 419/782 [00:19<00:11, 30.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420.0, Minibatch Loss= 0.997787, Training Accuracy= 0.53906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|                                                                             | 423/782 [00:19<00:11, 30.34it/s]\n",
      " 55%|                                                                            | 427/782 [00:19<00:11, 31.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 430.0, Minibatch Loss= 0.895947, Training Accuracy= 0.61719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|                                                                           | 431/782 [00:20<00:12, 28.88it/s]\n",
      " 56%|                                                                           | 435/782 [00:20<00:11, 30.01it/s]\n",
      " 56%|                                                                          | 439/782 [00:20<00:10, 31.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440.0, Minibatch Loss= 1.001835, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|                                                                         | 443/782 [00:20<00:11, 30.58it/s]\n",
      " 57%|                                                                        | 447/782 [00:20<00:10, 32.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 450.0, Minibatch Loss= 0.914880, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|                                                                       | 451/782 [00:20<00:10, 31.43it/s]\n",
      " 58%|                                                                      | 455/782 [00:20<00:11, 29.30it/s]\n",
      " 59%|                                                                      | 458/782 [00:20<00:11, 28.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460.0, Minibatch Loss= 0.894183, Training Accuracy= 0.64062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|                                                                     | 461/782 [00:21<00:11, 27.82it/s]\n",
      " 59%|                                                                    | 465/782 [00:21<00:10, 29.79it/s]\n",
      " 60%|                                                                   | 469/782 [00:21<00:10, 30.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 470.0, Minibatch Loss= 0.929136, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|                                                                  | 473/782 [00:21<00:10, 29.26it/s]\n",
      " 61%|                                                                  | 476/782 [00:21<00:10, 28.63it/s]\n",
      " 61%|                                                                 | 480/782 [00:21<00:10, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 480.0, Minibatch Loss= 1.049858, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|                                                                | 483/782 [00:21<00:10, 27.56it/s]\n",
      " 62%|                                                               | 487/782 [00:21<00:09, 29.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 490.0, Minibatch Loss= 0.965431, Training Accuracy= 0.57812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|                                                               | 491/782 [00:22<00:10, 28.69it/s]\n",
      " 63%|                                                              | 494/782 [00:22<00:10, 28.33it/s]\n",
      " 64%|                                                             | 497/782 [00:22<00:10, 28.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 500.0, Minibatch Loss= 0.927769, Training Accuracy= 0.60938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|                                                            | 501/782 [00:22<00:09, 28.58it/s]\n",
      " 65%|                                                           | 505/782 [00:22<00:09, 29.79it/s]\n",
      " 65%|                                                           | 509/782 [00:22<00:08, 30.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 510.0, Minibatch Loss= 0.999151, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|                                                          | 513/782 [00:22<00:09, 28.43it/s]\n",
      " 66%|                                                         | 517/782 [00:22<00:08, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 520.0, Minibatch Loss= 0.928518, Training Accuracy= 0.60156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|                                                        | 521/782 [00:23<00:08, 29.30it/s]\n",
      " 67%|                                                       | 525/782 [00:23<00:08, 30.19it/s]\n",
      " 68%|                                                      | 529/782 [00:23<00:07, 31.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 530.0, Minibatch Loss= 0.952003, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|                                                     | 533/782 [00:23<00:08, 30.75it/s]\n",
      " 69%|                                                     | 537/782 [00:23<00:08, 30.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 540.0, Minibatch Loss= 0.929418, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|                                                    | 541/782 [00:23<00:08, 29.19it/s]\n",
      " 70%|                                                   | 545/782 [00:23<00:07, 30.67it/s]\n",
      " 70%|                                                  | 549/782 [00:23<00:07, 31.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 550.0, Minibatch Loss= 0.943463, Training Accuracy= 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|                                                 | 553/782 [00:24<00:07, 30.47it/s]\n",
      " 71%|                                                | 557/782 [00:24<00:07, 30.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 560.0, Minibatch Loss= 0.971188, Training Accuracy= 0.63281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|                                               | 561/782 [00:24<00:07, 28.22it/s]\n",
      " 72%|                                               | 565/782 [00:24<00:07, 29.58it/s]\n",
      " 73%|                                              | 569/782 [00:24<00:06, 31.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 570.0, Minibatch Loss= 1.115926, Training Accuracy= 0.31250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|                                             | 573/782 [00:24<00:06, 30.24it/s]\n",
      " 74%|                                            | 577/782 [00:24<00:06, 31.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 580.0, Minibatch Loss= 0.925274, Training Accuracy= 0.57812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|                                           | 581/782 [00:25<00:06, 29.51it/s]\n",
      " 75%|                                          | 585/782 [00:25<00:06, 31.13it/s]\n",
      " 75%|                                         | 589/782 [00:25<00:06, 32.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 590.0, Minibatch Loss= 0.980424, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|                                        | 593/782 [00:25<00:06, 31.13it/s]\n",
      " 76%|                                        | 597/782 [00:25<00:05, 31.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 600.0, Minibatch Loss= 0.942857, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|                                       | 601/782 [00:25<00:06, 28.26it/s]\n",
      " 77%|                                      | 605/782 [00:25<00:06, 29.03it/s]\n",
      " 78%|                                     | 608/782 [00:25<00:05, 29.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 610.0, Minibatch Loss= 0.942976, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|                                     | 611/782 [00:26<00:06, 28.21it/s]\n",
      " 79%|                                    | 615/782 [00:26<00:05, 29.44it/s]\n",
      " 79%|                                   | 619/782 [00:26<00:05, 30.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 620.0, Minibatch Loss= 0.991773, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|                                  | 623/782 [00:26<00:05, 29.52it/s]\n",
      " 80%|                                 | 626/782 [00:26<00:05, 28.89it/s]\n",
      " 81%|                                | 630/782 [00:26<00:04, 30.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 630.0, Minibatch Loss= 0.922601, Training Accuracy= 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|                                | 634/782 [00:26<00:04, 29.93it/s]\n",
      " 82%|                               | 638/782 [00:26<00:04, 30.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 640.0, Minibatch Loss= 0.994773, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|                              | 642/782 [00:27<00:05, 27.95it/s]\n",
      " 82%|                             | 645/782 [00:27<00:04, 28.29it/s]\n",
      " 83%|                            | 649/782 [00:27<00:04, 29.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 650.0, Minibatch Loss= 0.974915, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|                            | 653/782 [00:27<00:04, 29.06it/s]\n",
      " 84%|                           | 657/782 [00:27<00:04, 29.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 660.0, Minibatch Loss= 0.955971, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|                          | 661/782 [00:27<00:04, 28.11it/s]\n",
      " 85%|                         | 665/782 [00:27<00:04, 28.43it/s]\n",
      " 85%|                        | 668/782 [00:27<00:03, 28.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 670.0, Minibatch Loss= 1.001524, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|                        | 671/782 [00:28<00:04, 27.61it/s]\n",
      " 86%|                       | 675/782 [00:28<00:03, 29.56it/s]\n",
      " 87%|                      | 679/782 [00:28<00:03, 31.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 680.0, Minibatch Loss= 0.975385, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|                     | 683/782 [00:28<00:03, 30.56it/s]\n",
      " 88%|                    | 687/782 [00:28<00:03, 31.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 690.0, Minibatch Loss= 0.960451, Training Accuracy= 0.53906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|                   | 691/782 [00:28<00:02, 30.79it/s]\n",
      " 89%|                  | 695/782 [00:28<00:02, 32.20it/s]\n",
      " 89%|                  | 699/782 [00:28<00:02, 31.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 700.0, Minibatch Loss= 0.886937, Training Accuracy= 0.63281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|                 | 703/782 [00:29<00:02, 30.50it/s]\n",
      " 90%|                | 707/782 [00:29<00:02, 31.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 710.0, Minibatch Loss= 0.906462, Training Accuracy= 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|               | 711/782 [00:29<00:02, 30.79it/s]\n",
      " 91%|              | 715/782 [00:29<00:02, 31.89it/s]\n",
      " 92%|             | 719/782 [00:29<00:01, 33.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 720.0, Minibatch Loss= 0.827357, Training Accuracy= 0.64844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|            | 723/782 [00:29<00:01, 31.70it/s]\n",
      " 93%|            | 727/782 [00:29<00:01, 32.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 730.0, Minibatch Loss= 0.990713, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|           | 731/782 [00:29<00:01, 31.82it/s]\n",
      " 94%|          | 735/782 [00:30<00:01, 32.65it/s]\n",
      " 95%|         | 739/782 [00:30<00:01, 31.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 740.0, Minibatch Loss= 0.924678, Training Accuracy= 0.58594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|        | 743/782 [00:30<00:01, 30.53it/s]\n",
      " 96%|       | 747/782 [00:30<00:01, 31.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 750.0, Minibatch Loss= 0.916248, Training Accuracy= 0.60938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|      | 751/782 [00:30<00:01, 29.11it/s]\n",
      " 96%|      | 754/782 [00:30<00:00, 29.11it/s]\n",
      " 97%|     | 758/782 [00:30<00:00, 30.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 760.0, Minibatch Loss= 0.884754, Training Accuracy= 0.63281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|    | 762/782 [00:30<00:00, 29.67it/s]\n",
      " 98%|   | 766/782 [00:31<00:00, 31.18it/s]\n",
      " 98%|  | 770/782 [00:31<00:00, 31.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 770.0, Minibatch Loss= 0.995937, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%| | 774/782 [00:31<00:00, 30.06it/s]\n",
      " 99%|| 778/782 [00:31<00:00, 30.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 780.0, Minibatch Loss= 0.911700, Training Accuracy= 0.61719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 782/782 [00:31<00:00, 27.54it/s]"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Use TQDM if installed\n",
    "tqdm_installed = False\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    tqdm_installed = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Launch the Tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# training_iterations_count: The number of data pieces to train on in total\n",
    "# batch_size: The number of data pieces per batch\n",
    "training_iterations = range(0,training_iterations_count,batch_size)\n",
    "if tqdm_installed:\n",
    "    # Add a progress bar if TQDM is installed\n",
    "    training_iterations = tqdm(training_iterations)\n",
    "\n",
    "for i in training_iterations:\n",
    "    if i % 1000 == 0:\n",
    "    # Select indices for a random data subset\n",
    "    batch = np.random.randint(data_feature_list[0].shape[0], size=batch_size)\n",
    "    \n",
    "    # Use the selected subset indices to initialize the graph's \n",
    "    #   placeholder values\n",
    "    hyps, evis, ys = (data_feature_list[0][batch,:],\n",
    "                      data_feature_list[1][batch,:],\n",
    "                      correct_scores[batch])\n",
    "    \n",
    "    # Run the optimization with these initialized values\n",
    "    sess.run([opt_op], feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "    # display_step: how often the accuracy and loss should \n",
    "    #   be tested and displayed.\n",
    "    if (i/batch_size) % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Calculate batch loss\n",
    "        tmp_loss = sess.run(loss, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Display results\n",
    "        print(\"Iter \" + str(i/batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(tmp_loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607871\n",
      "Positive / Positive\n",
      "0.785411\n",
      "Positive / Neutral\n",
      "0.690139\n",
      "Positive / Neutral\n",
      "0.781037\n",
      "Positive / Neutral\n",
      "0.78575\n",
      "Positive / Neutral\n",
      "0.767756\n",
      "Positive / Neutral\n",
      "0.764161\n",
      "Positive / Negative\n",
      "0.622069\n",
      "Positive / Neutral\n",
      "0.595884\n",
      "Positive / Neutral\n",
      "0.773022\n",
      "Positive / Positive\n",
      "0.742922\n",
      "Positive / Positive\n",
      "0.786698\n",
      "Positive / Negative\n",
      "0.654095\n",
      "Positive / Negative\n",
      "0.784147\n",
      "Positive / Neutral\n",
      "0.787508\n",
      "Positive / Neutral\n",
      "0.707686\n",
      "Positive / Positive\n",
      "0.783017\n",
      "Positive / Neutral\n",
      "0.786039\n",
      "Positive / Positive\n",
      "0.785771\n",
      "Positive / Positive\n",
      "0.585391\n",
      "Positive / Negative\n",
      "0.583182\n",
      "Positive / Neutral\n",
      "0.787316\n",
      "Positive / Neutral\n",
      "0.773115\n",
      "Positive / Positive\n",
      "0.697083\n",
      "Positive / Negative\n",
      "0.613348\n",
      "Positive / Positive\n",
      "0.68538\n",
      "Positive / Neutral\n",
      "0.762156\n",
      "Positive / Negative\n",
      "0.781782\n",
      "Positive / Positive\n",
      "0.604864\n",
      "Positive / Neutral\n",
      "0.711201\n",
      "Positive / Neutral\n",
      "0.781985\n",
      "Positive / Negative\n",
      "0.758357\n",
      "Positive / Negative\n",
      "0.78385\n",
      "Positive / Neutral\n",
      "0.662126\n",
      "Positive / Neutral\n",
      "0.735227\n",
      "Positive / Neutral\n",
      "0.583336\n",
      "Positive / Neutral\n",
      "0.744667\n",
      "Positive / Positive\n",
      "0.785534\n",
      "Positive / Positive\n",
      "0.786176\n",
      "Positive / Neutral\n",
      "0.785165\n",
      "Positive / Neutral\n",
      "0.786651\n",
      "Positive / Neutral\n",
      "0.708096\n",
      "Positive / Neutral\n",
      "0.788716\n",
      "Positive / Neutral\n",
      "0.784502\n",
      "Positive / Neutral\n",
      "0.78637\n",
      "Positive / Positive\n",
      "0.787153\n",
      "Positive / Positive\n",
      "0.786315\n",
      "Positive / Positive\n",
      "0.774933\n",
      "Positive / Neutral\n",
      "0.637819\n",
      "Positive / Neutral\n",
      "0.72865\n",
      "Positive / Neutral\n",
      "0.638973\n",
      "Positive / Neutral\n",
      "0.787982\n",
      "Positive / Positive\n",
      "0.590132\n",
      "Positive / Neutral\n",
      "0.788764\n",
      "Positive / Positive\n",
      "0.786021\n",
      "Positive / Positive\n",
      "0.768014\n",
      "Positive / Neutral\n",
      "0.635577\n",
      "Positive / Neutral\n",
      "0.61209\n",
      "Positive / Positive\n",
      "0.676879\n",
      "Positive / Positive\n",
      "0.761753\n",
      "Positive / Positive\n",
      "0.787184\n",
      "Positive / Positive\n",
      "0.77294\n",
      "Positive / Neutral\n",
      "0.57936\n",
      "Positive / Neutral\n",
      "0.665355\n",
      "Positive / Neutral\n",
      "0.672977\n",
      "Positive / Positive\n",
      "0.77197\n",
      "Positive / Neutral\n",
      "0.764021\n",
      "Positive / Neutral\n",
      "0.750373\n",
      "Positive / Neutral\n",
      "0.585164\n",
      "Positive / Neutral\n",
      "0.78712\n",
      "Positive / Neutral\n",
      "0.657463\n",
      "Positive / Neutral\n",
      "0.78751\n",
      "Positive / Negative\n",
      "0.632256\n",
      "Positive / Neutral\n",
      "0.66774\n",
      "Positive / Neutral\n",
      "0.782675\n",
      "Positive / Neutral\n",
      "0.782026\n",
      "Positive / Negative\n",
      "0.59398\n",
      "Positive / Neutral\n",
      "0.735314\n",
      "Positive / Negative\n",
      "0.786874\n",
      "Positive / Neutral\n",
      "0.602371\n",
      "Positive / Neutral\n",
      "0.782986\n",
      "Positive / Positive\n",
      "0.724599\n",
      "Positive / Neutral\n",
      "0.785836\n",
      "Positive / Neutral\n",
      "0.775014\n",
      "Positive / Negative\n",
      "0.757686\n",
      "Positive / Positive\n",
      "0.768383\n",
      "Positive / Neutral\n",
      "0.787013\n",
      "Positive / Neutral\n",
      "0.772179\n",
      "Positive / Positive\n",
      "0.785255\n",
      "Positive / Neutral\n",
      "0.787676\n",
      "Positive / Neutral\n",
      "0.631036\n",
      "Positive / Neutral\n",
      "0.686075\n",
      "Positive / Neutral\n",
      "0.723961\n",
      "Positive / Positive\n",
      "0.788102\n",
      "Positive / Neutral\n",
      "0.788283\n",
      "Positive / Neutral\n",
      "0.783878\n",
      "Positive / Neutral\n",
      "0.589054\n",
      "Positive / Neutral\n",
      "0.728862\n",
      "Positive / Neutral\n",
      "0.770985\n",
      "Positive / Positive\n",
      "0.694827\n",
      "Positive / Neutral\n",
      "0.786288\n",
      "Positive / Neutral\n",
      "0.73599\n",
      "Positive / Positive\n",
      "0.672577\n",
      "Positive / Negative\n",
      "0.774894\n",
      "Positive / Neutral\n",
      "0.758341\n",
      "Positive / Positive\n",
      "0.784098\n",
      "Positive / Positive\n",
      "0.708438\n",
      "Positive / Positive\n",
      "0.782541\n",
      "Positive / Neutral\n",
      "0.78963\n",
      "Positive / Neutral\n",
      "0.784645\n",
      "Positive / Neutral\n",
      "0.783595\n",
      "Positive / Negative\n",
      "0.638537\n",
      "Positive / Neutral\n",
      "0.646494\n",
      "Positive / Neutral\n",
      "0.667915\n",
      "Positive / Positive\n",
      "0.772946\n",
      "Positive / Positive\n",
      "0.681779\n",
      "Positive / Positive\n",
      "0.784914\n",
      "Positive / Negative\n",
      "0.785064\n",
      "Positive / Neutral\n",
      "0.787099\n",
      "Positive / Positive\n",
      "0.68629\n",
      "Positive / Positive\n",
      "0.618773\n",
      "Positive / Neutral\n",
      "0.728445\n",
      "Positive / Neutral\n",
      "0.613301\n",
      "Positive / Neutral\n",
      "0.790864\n",
      "Positive / Neutral\n",
      "0.786186\n",
      "Positive / Neutral\n",
      "0.694729\n",
      "Positive / Positive\n",
      "0.576839\n",
      "Positive / Neutral\n",
      "0.643821\n",
      "Positive / Neutral\n"
     ]
    }
   ],
   "source": [
    "evidences = [\"People wearing costumes are gathering in a forest and are looking in the same direction\"]\n",
    "hypotheses = [\"Masked people are looking in the same direction in a forest\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "sentence1 = [fit_to_size(np.vstack(sentence2sequence(evidence)[0]),\n",
    "                         (30, 50)) for evidence in evidences]\n",
    "\n",
    "sentence2 = [fit_to_size(np.vstack(sentence2sequence(hypothesis)[0]),\n",
    "                         (30,50)) for hypothesis in hypotheses]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def split_data_into_scores():\n",
    "    import csv\n",
    "    with open(\"training.txt\",\"r\") as data:\n",
    "        train = csv.DictReader(data , delimiter='\\t')\n",
    "        evi_sentences = []\n",
    "        hyp_sentences = []\n",
    "        labels = []\n",
    "        scores = []\n",
    "        count = 1\n",
    "        for row in train:\n",
    "            hyp_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence_A\"].lower())[0]))\n",
    "            evi_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence_B\"].lower())[0]))\n",
    "            labels.append(row[\"entailment_judgment\"])\n",
    "            scores.append(score_setup(row))\n",
    "        \n",
    "        hyp_sentences = np.stack([fit_to_size(x, (max_hypothesis_length, vector_size))\n",
    "                          for x in hyp_sentences])\n",
    "        evi_sentences = np.stack([fit_to_size(x, (max_evidence_length, vector_size))\n",
    "                          for x in evi_sentences])\n",
    "                                 \n",
    "        return (hyp_sentences, evi_sentences), labels, np.array(scores)\n",
    "data_feature_list, correct_values, correct_scores = split_data_into_scores()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hyps, evis, ys = (data_feature_list[0][batch,:],\n",
    "                  data_feature_list[1][batch,:],\n",
    "                  correct_scores[batch])\n",
    "predictions = sess.run(classification_scores, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "for i,prediction in enumerate(predictions):\n",
    "    print([\"Positive\", \"Neutral\", \"Negative\"][np.argmax(prediction[0])]+\n",
    "      \" / \" + [\"Positive\", \"Neutral\", \"Negative\"][np.argmax(ys[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
